---
title: "leroy_workspace"
author: "Leroy Bondhus"
date: "3/24/2021"
output: html_document
---


### set up libraries
```{r}
library("devtools")
library("roxygen2")
library("usedist")
library("ggtree")
install("./../GeneSpecificityFuncs")
```

```{r hierarchical_tree_funcs}
### ADDED TO PACKAGE (TRUE)
LMB_htf.create_node <- function(name = "...", dist_to_parent = -1,
                        left_child=NA, right_child=NA  ){
  return(list(name=name, dist_to_parent=dist_to_parent,
              left_child=left_child, right_child=right_child))
                        }


### ADDED TO PACKAGE (TRUE)
### test for whether or not any descendants of parent node have specified descendant_name
### By default considers a node to be a descendant of itself. 
### If self_descendant set to false, only child nodes and their descendants considered
LMB_htf.is_descendant <- function(parent_node, descendant_name, self_descendant = TRUE){
  if(all(is.na(parent_node))){return(FALSE)}   ## base case: if node does not exist it has no descendants
  if(parent_node$name == descendant_name & self_descendant==TRUE){return(TRUE)}
  else(return( LMB_htf.is_descendant(parent_node$left_child, descendant_name)
               | LMB_htf.is_descendant(parent_node$right_child, descendant_name)))
}

### ADDED TO PACKAGE (TRUE)
## return distance between two samples from dist_df
LMB_htf.pair_dist_from_dist_df <- function(dist_df, name1, name2 ){
  which <- which((dist_df$sample1 == name1 & dist_df$sample2 == name2) 
                 | (dist_df$sample1 == name2 & dist_df$sample2 == name1))
  return(dist_df[which,]$norm_distance)
}


## updates distance df to adjust for new_parent_node
## removes reference to new_parent_node descendants and replaces these with self reference
## uses functions: LMB_htf.is_descendant, LMB_htf.pair_dist_from_dist_df
LMB_htf.update_dist_df<-function(dist_df, new_parent_node){
  samples <- unique(c(as.character(dist_df$sample1),
                      as.character(dist_df$sample2)))
  
  ## test each samples for whether it is descendant of the new parent node
  which_desc <- apply(as.array(samples), MARGIN=1, FUN=LMB_htf.is_descendant, parent_node=new_parent_node)
  descendants <- samples[which_desc]
  not_descendants <- samples[!which_desc]
  
  if(length(not_descendants)==0){return(dist_df[0,])}
  new_par_combs <- cbind(expand.grid(new_parent_node$name, not_descendants), "norm_distance"=-1)
  colnames(new_par_combs) <- colnames(dist_df)
  for(i in 1:nrow(new_par_combs)){
    ## for each sample that is not a descendant of the new parent, get the minimum distance to a sample that is a descendant
    new_par_combs$norm_distance[i] <- min(apply(as.array(descendants), MARGIN=1,
                                         FUN=LMB_htf.pair_dist_from_dist_df,
                                         dist_df=dist_df, name1=levels(new_par_combs$sample2)[i]))
  }
  new_dist_df <- rbind(dist_df, new_par_combs)
  
  ## remove rows that are now redundant with coverage of new_parent_node
  which_remove <- which(is.element(new_dist_df$sample1,descendants) | is.element(new_dist_df$sample2,descendants) )
  new_dist_df <- new_dist_df[-which_remove,]
  return(new_dist_df) 
}


LMB_htf.sum_dist_of_children <- function(node){
  if(all(is.na(node$left_child)) != all(is.na(node$right_child))){print("WARNING: Asymetric Node"); return(-Inf)}
  if(all(is.na(node$left_child)) & all(is.na(node$right_child))){return(0)} ## if no children, return 0 as sum of distances
  left_sum <- node$left_child$dist_to_parent + LMB_htf.sum_dist_of_children(node$left_child)
  right_sum <- node$right_child$dist_to_parent + LMB_htf.sum_dist_of_children(node$right_child)
  if( abs(left_sum - right_sum) > 1e-10 ){print("WARNING: Asymetric Node"); return(-Inf)}  ## test for equality sometimes fails, test diff less than small number
  else(return(left_sum))
}


## dist_df is object passed and object that will control tree build
LMB_htf.dist_tree <- function(dist_df=dist_df, is_rooted=F){
  samples <- unique(c(as.character(dist_df$sample1),
                      as.character(dist_df$sample2)))
  node_list <- list()
  for(i in 1:length(samples)){
    node_list[[samples[i]]] <- LMB_htf.create_node(name=samples[i])
  }
  
  parent_index <- 1
  while(nrow(dist_df) > 0){
    print(parent_index)
    min_pair <- dist_df[which(dist_df$norm_distance==min(dist_df$norm_distance)),]
    if(nrow(min_pair) > 1){print("WARNING: tie in minimum pair")}
    ## connect pair to a common parent node
    left_child <- node_list[[min_pair$sample1]]; right_child <- node_list[[min_pair$sample2]]
    left_child$dist_to_parent <- min_pair$norm_distance - LMB_htf.sum_dist_of_children(left_child); 
    right_child$dist_to_parent <- min_pair$norm_distance - LMB_htf.sum_dist_of_children(right_child);
    parent_node <- LMB_htf.create_node(name = paste("p",parent_index,sep = ""), left_child = left_child, right_child = right_child )
    
    ## update node list
    node_list <- node_list[which(names(node_list) != min_pair$sample1 & names(node_list) != min_pair$sample2 )]
    node_list[[parent_node$name]] <- parent_node
    
    ## update dist_df to include new parent_node and pairwise distance (min distance to any child)
    dist_df <- LMB_htf.update_dist_df(dist_df=dist_df, new_parent_node=parent_node)

    ## repeat until dist_df is empty (which implies everything is connect)
    parent_index <- parent_index+1
    print(parent_index)
  }
  
  
  ### rooting might not be necessary for generality -- can also pull this out and build distance matrix with a root with dist to all samples set to 1.
  if(is_rooted){
    node_list$name <- "root"
    node_list$p4$dist_to_parent <- 1 - LMB_htf.sum_dist_of_children(node_list$p4) ## when rooted forces domain to cover 0-1 by making dist to root 1 for all samples
    return(node_list)
  }
  parent_node$dist_to_parent <- 1 - LMB_htf.sum_dist_of_children(parent_node)  ## distance is distance to an abstract root 
  return(parent_node)

}

```

### building distance tree functions
```{r}

# simulate some genes
genes <- letters[1:1000]
samples <- paste("s", as.character(1:5), sep = "")
mat <- matrix(nrow=length(genes), ncol=length(samples))
for(i in 1:length(samples)){
  mat[,i] <- rnorm(length(genes))
}

## let samples 2 and 3 be descendants of 1
for(i in 2:3){
  mat[,i] <- mat[,1] + rnorm(length(genes)) * 0.1 ## simulate technical noise 
  gsamp <- sample(1:length(genes), sample(50:150, 1))  ##
  mat[gsamp,i] <- rnorm(length(gsamp))
}

## calculate distance matrix
dist_mat <- matrix(nrow = length(samples), ncol = length(samples))
dist_mat <- dist(t(mat), diag = F, upper = F)
dist_mat_norm <- dist_mat / max(dist_mat)  ## constrain domain of distance values to 0-1
dist_df_temp <- data.frame(t(combn(samples,2)), as.numeric(dist_mat_norm), stringsAsFactors = F)
names(dist_df_temp) <- c("sample1","sample2", "norm_distance")
hist(dist_mat_norm,breaks = 1000)


distance_tree <- GeneSpecificityFuncs::LMB_htf.dist_tree(dist_df = dist_df_temp)


#### convert distance_tree to plottable format
#### suggested packages: data.tree (convert between yaml)
#### suggested plan: save distance tree as yaml for conversion
####                 and then ggtree for plotting


hclus <- hclust(dist_mat_norm)
as.dendrogram(hclus)
plot(hclus)

```


```{r test dendextend}
library(dendextend)
dend <- c(1:5) %>% dist %>% hclust(method="average") %>% as.dendrogram

dend %>% plot
dend %>% unclass %>% str
```



```{r set up project map}

### aim: calculate gene expression specificity integrating sample similarity information

### load dataset :: genes(rows) x samples(cols) ## matrix or dataframe  
###### standardize format and metadata organization

### calculate sample similarity matrix 
###### test different methods for doing this (Yenifer)

### generate sample similarity tree
###### test different methods for doing this (Yenifer)

### use similarity tree to calculate sample weights 

### use sample weights to draw distribution of gene expression across all samples (Roshni)

### calculate gene specificity values (Roshni)




```


```{r temp_consolidate_with_main_tomorrow_08262021}

### note: should add the weight calculation step inside this function
## e.g. Feed in P1, P2, n, num_perm,
## also Feed in similarity function, clustering function (since these might be variable later)
## calc similarity matrix -> calc similarity tree -> calc sample weights

appended_te_to_weighted_zscore <- function(P1,P2,weights,size_of_selection,number_of_permutations){
  results_list <- list()
  for (i in 1:size_of_selection){
    for (j in 1:number_of_permutations){
      selected_columns <- sample(P2, size_of_selection)
      df <- data.frame(P1,selected_columns)
      weights_sub <- left_join(data.frame(name=colnames(df)),weights,by="name")
      weighted_te_matrix <- matrix(nrow=nrow(df),ncol=ncol(df))
      for (i in 1:nrow(weight_vector)){
        weighted_te_matrix[,i] <- weight_vector[i,2]*df[,i]
      }
      colnames(weighted_te_matrix) <- colnames(df)
      weighted_means <- c(1:nrow(weighted_te_matrix))
      sum_of_weights <- sum(weight_vector[,2])
      for (i in 1:nrow(weighted_te_matrix)){
        weighted_means[i] <- sum(weighted_te_matrix[i,]) / sum_of_weights
      }
      weighted_var <- matrix(nrow=nrow(df),ncol=1)
      for (i in 1:nrow(df)){
        weighted_var[i] <- wtd.var(df[i,],weights=weight_vector[,2])
      }
      weighted_sd <- sqrt(weighted_var)
      for (i in 1:nrow(df)){
        df[i,] <- (df[i,]-weighted_means[i])/weighted_sd[i]
      }
      weighted_zscores <- na.omit(df)
      weighted_zscores <- weighted_zscores[,1:ncol(P1)]
      output <- list(weighted_zscores)
      results_list <- append(results_list,output)
    }
  }
  return(results_list)
}

```
