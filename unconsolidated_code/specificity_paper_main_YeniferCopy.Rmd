---
title: "specificity_paper_main_YeniferCopy"
output: html_document
---

## NOTE: most functions live in GeneSpecificityFuncs package for 
##       this project. Load this package here
## 
```{r set up package of functions used}
library("devtools")
library("roxygen2")

```

```{r libraries}
library(ggplot2)
```

## load gtex here
```{r import dataset}
## import gtex medians data
 temp <- tempfile()
download.file("https://storage.googleapis.com/gtex_analysis_v8/rna_seq_data/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct.gz",temp)
gtex <- read.table( temp, skip=2, header = TRUE, sep = "\t")
gtex_rowinfo <- data.frame(Name=gtex$Name, Description=gtex$Description)
rownames(gtex) <- gtex$Name
gtex <- as.matrix(gtex[,3:ncol(gtex)])
unlink(temp); rm(temp)


#BiocManager::install("biomaRt")
library(biomaRt)
## import ensembl gene data
ensembl = useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl", GRCh=37)
genes <- getBM(attributes=c('chromosome_name','start_position','end_position','hgnc_symbol', 'ensembl_gene_id','gene_biotype'),
                 filters = list('biotype'='protein_coding'),
                 mart = ensembl, useCache = F) 
genes <- genes[which(is.element(genes$chromosome_name, c(1:22, "X", "Y", "MT")) & genes$hgnc_symbol != "" ) ,]



```

## clean gtex dataset here
```{r clean dataset}
## show mitochondrial genes drive a large part of sample similarity
## Note sum of medians in gtex not quite 1M - likely artifact of taking medians
barplot(colSums(gtex))
library(stringr)
## match genes between gtex and ensembl
gtex_names <- str_split_fixed(gtex_rowinfo$Name, "[.]", 2)[,1]
which <- which(genes$chromosome_name != "MT" )
gtex_cleaned <- gtex[which(is.element(gtex_names, genes$ensembl_gene_id[which])),]
which <- which(genes$chromosome_name == "MT" )
gtex_cleanedMT <- gtex[which(is.element(gtex_names, genes$ensembl_gene_id[which])),]

##non-mitochondrial TPM sum
barplot(colSums(gtex_cleaned))
##mitochondrial TPM sum
barplot(colSums(gtex_cleanedMT))
## non-mito + mito TPM sum
barplot(colSums(gtex_cleaned)+colSums(gtex_cleanedMT))
rm(gtex_cleanedMT)
##renormalize TPM without mitochondrial genes
for(i in 1:ncol(gtex_cleaned)){
  gtex_cleaned[,i] <- (gtex_cleaned[,i]*1e6 / sum(gtex_cleaned[,i]))
}
barplot(colSums(gtex_cleaned))

#### Supplemental Figure (Fraction of TPM from chr==M )
gtex <- gtex_cleaned; rm(gtex_cleaned)
exp_mat <- gtex
## log10(TPM+1) transform of data
exp_mat <- log10(exp_mat+1)

#### Supplemental Figure (heatmap cluster of samples )

## remove mitochondrial contribution
```


```{r measure sample similarity}
### to do: justify method for measuring sample similarity - may require comparison or refs

####ADDED
calc_manhattan_matrix<- function(dat) {
   manhatt<- matrix(0, nrow = ncol(dat), ncol = ncol(dat))
  for(i in 1:ncol(dat)){
    for(j in 1:ncol(dat)) {
       x<-dat[,i]
       y<-dat[,j]
       manhatt[j,i]<-sum(x[i]-x[j] + y[i]-y[j])
    }
  }
    
  return(manhatt)
}


manhat_matrix<- (calc_manhattan_matrix(exp_mat))
library(reshape2)
library(ggplot2)

manhat_matrix<-melt(manhat_matrix)
  ggplot(manhat_matrix, aes(x = Var2, y = Var1)) + 
  geom_raster(aes(fill=value)) + 
  scale_fill_gradient(low="white", high="red") +
  labs(x="Tissue", y="Tissue", title="Manhattan Distance") +
  theme_bw() + theme(axis.text.x=element_text(size=7, angle=90, vjust=.1),
                     axis.text.y=element_text(size=7),
                     plot.title=element_text(size=11)) 








calc_mean_char_dif_matrix<- function(dat) {
   mcd<- matrix(0, nrow = ncol(dat), ncol = ncol(dat))
  for(i in 1:ncol(dat)){
    for(j in 1:ncol(dat)) {
       x<-dat[,i]
       y<-dat[,j]
       h<-sum(abs(x[i]-x[j] + y[i]-y[j]))
       n<-(1/i) * h
       mcd[j,i]<- n 
    }
  }
    
  return(mcd)
}
mcd_mat<-(calc_mean_char_dif_matrix(exp_mat))

library(reshape2)
library(ggplot2)

mcd_mat<-melt(mcd_mat)
  ggplot(mcd_mat, aes(x = Var2, y = Var1)) + 
  geom_raster(aes(fill=value)) + 
  scale_fill_gradient(low="white", high="red") +
  labs(x="Tissue", y="Tissue", title="Mean Character Difference ") +
  theme_bw() + theme(axis.text.x=element_text(size=7, angle=90, vjust=.1),
                     axis.text.y=element_text(size=7),
                     plot.title=element_text(size=11)) 



calc_canberra_matrix<- function(dat) {
   canberra<- matrix(0, nrow = ncol(dat), ncol = ncol(dat))
  for(i in 1:ncol(dat)){
    for(j in 1:ncol(dat)) {
       x<-dat[,i]
       y<-dat[,j]
       h<-sum(abs(x[i]-x[j] + y[i]-y[j]))
       g<-sum(x[i]+x[j] + y[i]+y[j])
       n<-h/g
        if(is.na(n)){
         n = 0
       }
       canberra[j,i]<- n 
    }
  }
    
  return(canberra)
}

canberra_mat<- (calc_canberra_matrix(exp_mat))
  
#canberra 

library(reshape2)
library(ggplot2)

canberra_mat<-melt(canberra_mat)
  ggplot(canberra_mat, aes(x = Var2, y = Var1)) + 
  geom_raster(aes(fill=value)) + 
  scale_fill_gradient(low="white", high="red") +
  labs(x="Tissue", y="Tissue", title="Canberra ") +
  theme_bw() + theme(axis.text.x=element_text(size=7, angle=90, vjust=.1),
                     axis.text.y=element_text(size=7),
                     plot.title=element_text(size=11)) 


  
calc_coefficient_divergence<- function(dat) {
   cdiv<- matrix(0, nrow = ncol(dat), ncol = ncol(dat))
  for(i in 1:ncol(dat)){
    for(j in 1:ncol(dat)) {
       x<-dat[,i]
       y<-dat[,j]
       h<-sum(x[i]-x[j] + y[i]-y[j])
       g<-sum(x[i]+x[j] + y[i]+y[j])
       n<-h/g
       n = n^2 
       n = n * (1/54)
       n = n^(1/2)
       if(is.na(n)){ #unsure whether to leave NA values or convert them to 0
         n = 0
       }
       cdiv[j,i]<- n 
    }
  }
    
  return(cdiv)
}

cod_matrix<-(calc_coefficient_divergence(exp_mat))

#coefficient of divergence 

library(reshape2)
library(ggplot2)

cod_matrix<-melt(cod_matrix)
  ggplot(cod_matrix, aes(x = Var2, y = Var1)) + 
  geom_raster(aes(fill=value)) + 
  scale_fill_gradient(low="white", high="red") +
  labs(x="Tissue", y="Tissue", title="Coefficient of divergence   ") +
  theme_bw() + theme(axis.text.x=element_text(size=7, angle=90, vjust=.1),
                     axis.text.y=element_text(size=7),
                     plot.title=element_text(size=11)) 

######

calc_zscore_matrix<- function(dat) {
  zscores <- dat; zscores[] <- 0 
  means <- rowMeans(dat)
  sds <- as.numeric(rep(NA,length(means)))
  which <- which(means != 0)
  sds[which] <- apply(dat[which,],1,sd)
  for(j in 1:ncol(dat)){zscores[,j] <- (dat[,j] - means)/sds  }
  return(zscores)
}

calc_dot_product_similarity_matrix <- function(dat) {
  dot_product_similarity_matrix <- matrix(0, nrow = ncol(dat), ncol = ncol(dat))
  colnames(dot_product_similarity_matrix) <- colnames(dat)
  rownames(dot_product_similarity_matrix) <- colnames(dat)
  for(i in 1:ncol(dat)){
    for(j in 1:ncol(dat)){
      which_i <- which(!is.na(dat[,i])) ## ignore NAs
      which_j <- which(!is.na(dat[,j])) ## ignore NAs
      dot_product_similarity_matrix[i,j] <- sum(dat[which_i,i] * dat[which_j,j]) / (norm(dat[which_i,i],"2")*norm(dat[which_j,j],"2"))
    }
  }
  return(dot_product_similarity_matrix)
}

## together these are a similarity function 
zscores <- calc_zscore_matrix(exp_mat) 
dot_sim <- calc_dot_product_similarity_matrix(zscores)

### validate choice
##use dist=1-dot_sim(zscores(log10(tpm+1))), single linkage clustering for now 
plot(hclust(as.dist(1-dot_sim),method = "single"), hang = -1, main = "dot_sim,single_clust")
sim_mat <- dot_sim
### create: sim_mat # sample similarity matrix

#####ADDED
library(reshape2)
library(ggplot2)

#sim_mat

library(reshape2)
library(ggplot2)

simi_mat<-melt(sim_mat)
  ggplot(simi_mat, aes(x = Var2, y = Var1)) + 
  geom_raster(aes(fill=value)) + 
  scale_fill_gradient(low="white", high="red") +
  labs(x="Tissue", y="Tissue", title="Z-scores") +
  theme_bw() + theme(axis.text.x=element_text(size=7, angle=90, vjust=.1),
                     axis.text.y=element_text(size=7),
                     plot.title=element_text(size=11)) 

######


```


```{r hierarchical clustering on sample similarity}
### to do: justify method for hierarchical clustering - may require comparison or refs

sim_tree <- as.dendrogram(hclust(as.dist(1-dot_sim),method = "single"))

### create: sim_tree # sample similarity tree
```


```{r calculate sample weights}
### uses Equation 1. 
## modelled on Yenifer's code
add_dist_to_parent <- function(dend, dist_to_parent=0){
  ## note: distance to parent is fed in at the start of the function
  attributes(dend) <- c(attributes(dend), dist_to_parent=dist_to_parent)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    ## distance to parent is simply the difference in height between parent and child
    dist_to_parent <- attributes(dend)$height - attributes(dend[[i]])$height 
    dend[[i]] <- add_dist_to_parent(dend[[i]], 
                                             dist_to_parent = dist_to_parent)
  }
  return(dend)
}
sim_tree <- add_dist_to_parent(sim_tree)

## modelled on Yenifer's code
add_weights <- function(dend, weight_of_parent=0){
  weight <- (attributes(dend)$dist_to_parent / attributes(dend)$members) + weight_of_parent 
  attributes(dend) <- c(attributes(dend), weight=weight)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    dend[[i]] <- add_weights(dend[[i]], weight_of_parent=weight)
  }
  return(dend)
}


get_weights <- function(dend, name_order){
  weights <- setNames(get_leaves_attr(sim_tree,"weight"),nm=get_leaves_attr(sim_tree,"lab") )
  weights <- weights[order(factor(names(weights),levels = name_order))]
  return(weights)
}


sim_tree <- add_weights(sim_tree)

## plot tree with weights
library(dendextend)
sim_tree %>% set("nodes_pch",19) %>% set("nodes_cex", 2.2*sqrt(get_nodes_attr(sim_tree,"weight"))) %>% plot


weights <- get_weights(sim_tree, colnames(exp_mat))

ggplot( data.frame(names=names(weights), weights=weights),aes(x=names, y=weights))+
  geom_col()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

### create: weights
```


```{r calculate specificity}
library(dplyr)
library('Hmisc')
## order weights to match columns of expression matrix


weights <- get_weights(sim_tree, colnames(exp_mat))



# function to calculate weighted zscores
## was te_to_weighted_zscore
## now assumes weights are sorted in same order at mat samples
calc_weighted_zscore_matrix <- function(mat, weights){
  if(any( colnames(mat) != names(weights) )){print("WARNING: mismatch in weights names and matrix colnames order")}
  weighted_mat <- mat; weighted_mat[] <- 0
  for (i in 1:length(weights)){
    weighted_mat[,i] <- weights[i]*mat[,i]
  }
  weighted_means <- numeric(length = nrow(weighted_mat))
  sum_of_weights <- sum(weights)
  for (i in 1:nrow(weighted_mat)){
    weighted_means[i] <- sum(weighted_mat[i,]) / sum_of_weights
  }
  weighted_var <- numeric(length=nrow(mat))
  for (i in 1:nrow(mat)){
    weighted_var[i] <- wtd.var(mat[i,],weights=weights)
  }
  weighted_sd <- sqrt(weighted_var)
  for(i in 1:ncol(mat)){
    mat[,i] <- (mat[,i]-weighted_means)/weighted_sd
  }
  weighted_zscores <- mat
  return(weighted_zscores)
}

spec_mat_weighted <- calc_weighted_zscore_matrix(exp_mat, weights)
#flat <- weights; flat[1:length(flat)] <- 1
spec_mat_flat  <- calc_weighted_zscore_matrix(exp_mat, flat)
plot(as.matrix(spec_mat_weighted),as.matrix(spec_mat_flat))

plot(spec_mat_weighted[,grep("Brain",colnames(spec_mat_flat))],spec_mat_flat[,grep("Brain",colnames(spec_mat_flat))])

abline(h=c(0,2,4), v=c(0,2,4))

abline(0,1, col="red")
### use Roshni's Code



### creates: spec_mat # specificity matrix
```



```{r validation with variable sample set,eval=FALSE}
if(FALSE){
## for i in 1:num(brain_samples)
# get P1 and P2
# expression mat -> calc sample sim -> create tree -> calc weight -> specificity 
# save results
# compare

### generalizing a list to store results in - this will make it easier to extend later if necessary.
## Note: only need the weighted version of each equation as each simplifies to flat version when all weights are 1
specificity_measures <- list(func_names=c("Zscore", "Tau", "Tsi","Gini"),
                             funcs=list(Zscore=calc_weighted_zscore_matrix,
                                        Tau=NA,
                                        Tsi=NA,
                                        Gini=NA
                             ))
robustness_test_results <- list( )
for(i in 1:length(specificity_measures$func_names)){
  el_names <- paste( c( "P1_", "P2_")
                     , specificity_measures$func_names[i], sep="")
  temp_list <- setNames(list(list(), list()), nm=el_names  )
  robustness_test_results <- c(robustness_test_results, temp_list )
}


### note: should add the weight calculation step inside this function
## e.g. Feed in P1, P2, n, num_perm,
## also Feed in similarity function, clustering function (since these might be variable later)
## calc similarity matrix -> calc similarity tree -> calc sample weights

library(doParallel)
library(foreach)
registerDoParallel(detectCores())


num_brain_samples <- length(colnames(exp_mat)[grep("[Bb]rain",colnames(exp_mat))])
num_reps <- 1
## use general similarity_func and cluster_func in case we want to test more later
similarity_func <- function(exp_mat){calc_dot_product_similarity_matrix(calc_zscore_matrix(exp_mat))}
cluster_func <- function(sim_mat){add_weights(add_dist_to_parent(as.dendrogram(hclust(as.dist(1-sim_mat), method = "single") ) ))}  

## P1 and notP1 are contant throughout, so set these outside loops
P1 <- as.matrix(exp_mat[,grep("[Bb]rain",colnames(exp_mat), invert = TRUE)])
notP1 <- as.matrix(exp_mat[,grep("[Bb]rain",colnames(exp_mat), invert = FALSE)])

### define 1-n trajectories ahead of time since i+1 should be referenced against i.
## do foreach over each element of permuation matrix ## use arrayInd to get row/col given perm number
permutation_matrix <- matrix(nrow = num_brain_samples, ncol = num_reps )
for(rep in 1:num_reps){
  permutation_matrix[,rep] <- sample(colnames(notP1),num_brain_samples, replace = FALSE)
}


for(measure in specificity_measures$func_names){
  specificity_func <- specificity_measures$funcs[[measure]]
  if(!is.function(specificity_func)){print(paste(measure, "func is not a function")); next;}
  
    results <- foreach(perm=1:length(permutation_matrix), .final = function(x) setNames(x,paste("rep=", arrayInd(1:length(permutation_matrix), dim(permutation_matrix))[,2], ",n=", arrayInd(1:length(permutation_matrix), dim(permutation_matrix ))[,1], sep = ""))) %dopar% {
    library('Hmisc')
    library(dendextend)
    sample_indices <- 1:arrayInd(perm, dim(permutation_matrix))[1] ## row is sample name, all names in a row up to top are choices for n=1,2..i
    rep_index <- arrayInd(perm, dim(permutation_matrix))[2] ## column is replicate number
    sample_set <- permutation_matrix[sample_indices, rep_index]
    
    # P1_baseline is just P1 at n=1
    P2 <- notP1[,sample_set, drop=F]; colnames(P2) <- make.unique(colnames(P2)) ## make.unique will facilitate sampling with replacement
    P1uP2 <- cbind(P1,P2)
    
    ## P1uP2 ## exp_mat > get sim mat > get sim tree > get samp weights > get spec mat
    sim_mat <- similarity_func(P1uP2)
    sim_tree <- cluster_func(sim_mat)
    weights <- get_weights(sim_mat, colnames(P1uP2))
    flat <- weights; flat[] <- 1
    spec_mat_flat <- specificity_func(P1uP2, flat)
    spec_mat_weighted <- specificity_func(P1uP2, weights)
    
    # need to fill in these with spec_score matrices for each n for each method
    # names should match 
    result <- list(
      P1_weighted_spec_score = spec_mat_weighted[,colnames(P1), drop=F],
      P1_flat_spec_score = spec_mat_flat[,colnames(P1), drop=F],
      P2_weighted_spec_score = spec_mat_weighted[,colnames(P2), drop=F],
      P2_flat_spec_score = spec_mat_flat[,colnames(P2), drop=F]
    )
    }
    
    results_P1 <- list()
    results_P2 <- list()
    for(i in 1:length(results)){
      name <- names(results)[i]
      rep <- str_split_fixed(names(results)[1], "[=,]", n=4)[,2]
      n <- str_split_fixed(names(results)[1], "[=,]", n=4)[,4]
      results_P1[[name]] <- list(P1_weighted_spec_score = results[[name]]$P1_weighted_spec_score, P1_flat_spec_score = results[[name]]$P1_flat_spec_score)
      results[[name]]$P1_weighted_spec_score <- NULL;  results[[name]]$P1_flat_spec_score <- NULL;  ## large object so delete as we go to avoid copy
      
      results_P2[[name]] <- list(P2_weighted_spec_score = results[[name]]$P2_weighted_spec_score, P2_flat_spec_score = results[[name]]$P2_flat_spec_score)
      results[[name]]$P2_weighted_spec_score <- NULL;  results[[name]]$P2_flat_spec_score<- NULL;  ## large object so delete as we go to avoid copy
    }
    
    robustness_test_results[[paste("P1_", measure,sep = "")]] <- results_P1; rm(results_P1)
    robustness_test_results[[paste("P2_", measure,sep = "")]] <- results_P2; rm(results_P2)
}


if(FALSE){ ### these are useful for rough look at trends
  for(rep in 1: 1){  # ncol(permutation_matrix)){
    for(n in 1:nrow(permutation_matrix)){
      name <- paste("rep=", rep,",n=",n, sep="")
      name_baseline <- paste("rep=", rep,",n=",1, sep="")
      plot(robustness_test_results$P1_Zscore[[name_baseline]]$P1_flat_spec_score[,"Spleen"], robustness_test_results$P1_Zscore[[name_baseline]]$P1_flat_spec_score[,"Spleen"]-robustness_test_results$P1_Zscore[[name]]$P1_flat_spec_score[,"Spleen"], main = paste("P1 flat:n =",n))
    }
  
    for(n in 1:nrow(permutation_matrix)){
      name <- paste("rep=", rep,",n=",n, sep="")
      name_baseline <- paste("rep=", rep,",n=",1, sep="")
      plot(robustness_test_results$P1_Zscore[[name_baseline]]$P1_weighted_spec_score[,"Spleen"], robustness_test_results$P1_Zscore[[name_baseline]]$P1_weighted_spec_score[,"Spleen"]-robustness_test_results$P1_Zscore[[name]]$P1_weighted_spec_score[,"Spleen"], main = paste("P1 weighted:n =",n))
    }
  
    for(n in 1:nrow(permutation_matrix)){
      name <- paste("rep=", rep,",n=",n, sep="")
      name_baseline <- paste("rep=", rep,",n=",1, sep="")
      plot(robustness_test_results$P2_Zscore[[name_baseline]]$P2_flat_spec_score[,1], robustness_test_results$P2_Zscore[[name_baseline]]$P2_flat_spec_score[,1]- robustness_test_results$P2_Zscore[[name]]$P2_flat_spec_score[,1], main = paste("P2 flat:n =",n))
      }
  
    for(n in 1:nrow(permutation_matrix)){
      name <- paste("rep=", rep,",n=",n, sep="")
      name_baseline <- paste("rep=", rep,",n=",1, sep="")
      plot(robustness_test_results$P2_Zscore[[name_baseline]]$P2_weighted_spec_score[,1], robustness_test_results$P2_Zscore[[name_baseline]]$P2_weighted_spec_score[,1]- robustness_test_results$P2_Zscore[[name]]$P2_weighted_spec_score[,1], main = paste("P2 weighted:n =",n))
    }
  }
}
}

## output to look at is robustness_test_results
```

```{r}

if (!require("RColorBrewer")) {
install.packages("RColorBrewer")
library(RColorBrewer)
}

display.brewer.all()

 get_gene<- function(gene_name,data_set){
   gtex[gene_name,]
 }
 #"" on gene_name 
 get_gene("ENSG00000227232.5",gtex)
 

  

 add_gene_exp <- function(dend, vect){
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    gene_exp<-vect[attributes(dend)$label]
    print(gene_exp)
    attributes(dend)<- c(attributes(dend), gene_exp=gene_exp)
    return(dend)
   }
  
  for(i in 1:length(dend)){ 
    dend[[i]] <- add_gene_exp(dend[[i]],vect)
  }
  return(dend)
 }
vect<-get_gene("ENSG00000227232.5",gtex)
stree<-add_gene_exp(sim_tree,vect)
attributes(stree)
attributes(stree)$gene_exp
#mapping between colors and values 
library(RColorBrewer)
library(ggplot2)


install.packages("scales")
library("scales")
pal <- col_numeric(palette = "Blues",domain =(get_leaves_attr(stree,"gene_exp")))
library(dendextend)
attributes(stree)
pal
temp_colors <-brewer.pal(5,"Blues")
stree %>% set("leaves_pch",19) %>%set("leaves_cex",2*(get_leaves_attr(stree,"weight")))%>%set("leaves_col",pal(get_leaves_attr(stree,"gene_exp"))) %>%plot 
(get_leaves_attr(stree,"gene_exp"))[1:7]
(get_leaves_attr(stree,"label"))[1:7]
stree %>%set("leaves_col",pal(get_leaves_attr(stree,"gene_exp"))) %>%plot 

 
(get_leaves_attr(stree,"gene_exp"),"Blues")
#add lines to dendrogram 
#spec_mat_flat/weighted greatest difference between them 
#compiling list of different markers 
#size of node/expression 
#color specificity value
```
#Reweighting weights functions 
```{r}
  get_weights <- function(dend, name_order){
  weights <- setNames(get_leaves_attr(dend,"weight"),nm=get_leaves_attr(dend,"lab") )
  weights <- weights[order(factor(names(weights),levels = name_order))]
  return(weights)
   }

weight1<-function(dat){
  zcores_w<-calc_zscore_matrix(exp_mat)
   dot_sim_w<-calc_dot_product_similarity_matrix(zcores_w)
   sim_mat_w <- dot_sim_w
   sim_tree_w <- as.dendrogram(hclust(as.dist(1-dot_sim_w),method = "single"))
   sim_tree_w <- add_dist_to_parent(sim_tree_w)
   sim_tree_w <- add_weights(sim_tree_w)
   weights_w <- get_weights(sim_tree_w, colnames(exp_mat))
  
}
weight2<-function(dat,weights_w){
  mat_weighted <- calc_weighted_zscore_matrix(exp_mat, weights_w)
   dot_sim_w2<-calc_dot_product_similarity_matrix(mat_weighted)
   sim_mat_w2 <- dot_sim_w2
   sim_tree_w2 <- as.dendrogram(hclust(as.dist(1-dot_sim_w2),method = "single"))
   sim_tree_w2 <- add_dist_to_parent(sim_tree_w2)
   sim_tree_w2 <- add_weights(sim_tree_w2)
   weights_w2 <- get_weights(sim_tree_w2, colnames(exp_mat))
}



comparing_weights<-function(w_1,w_2){
  
      which_i <- which(!is.na(w_1)) ## ignore NAs
      which_j <- which(!is.na(w_2)) ## ignore NAs
      dot_product_weight <- sum(which_i * which_j) / (norm(which_i,"2")*norm(which_j,"2"))
      
      return(dot_product_weight)
}



cosine_simi<-function(x,y){
product_xy <- x * y
sum_xy <- sum(product_xy)
magnitude_x <- x^2
magnitude_x<- sum(magnitude_x)
magn_x <- sqrt(magnitude_x)
magnitude_y <- y^2
magnitude_y <- sum(magnitude_y)
magn_y <- sqrt(magnitude_y)
magn_z <- magn_x * magn_y
cos_sin <-  sum_xy/magn_z
return(cos_sin)
}


```
#iteration function
```{r}

weight_simi_it<-function(dat){
  pct = 4 
count = 0 
original_weight_1<-weight1(exp_mat)
weight_1<-weight1(exp_mat)
while(pct > .01){
 count = count + 1
 weight_2<-weight2(exp_mat,weight_1)
 pct<-cosine_simi(original_weight_1,weight_2)/100
 weight_1<-weight_2
}
print(pct)
return(count)
}
weight_simi_it(exp_mat)
```

#gene ontology 
```{r}

#if flat > weight 
#if flat < weight 
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

BiocManager::install("clusterProfiler")
BiocManager::install("DOSE")
BiocManager::install("org.Hs.eg.db")
BiocManager::install("pathview")
library(DOSE)
library(pathview)
library(clusterProfiler)
library(org.Hs.eg.db)


tem <- tempfile()
download.file("https://raw.githubusercontent.com/hbctraining/DGE_workshop_salmon_online/master/data/annotations_ahb.csv",tem)
annotations_ahb<- read.table( tem, skip=0, header = TRUE, sep = ",")
```
#finding specific genes 
```{r}
 library(tidyverse)
y<-rownames(spec_mat_flat)
gene_names<-str_split_fixed(y,"[.]",2)
gene_names<-gene_names[,1]
gene_names[1]
tissue_names<-colnames(spec_mat_flat)
x
genes_spec <- data.frame(NULL,NULL,NULL,NULL)

########
for(j in 1:ncol(spec_mat_weighted)){
 for(i in 1:nrow(spec_mat_weighted)){ #get rid of loop
      if(is.na(spec_mat_flat[i,j]>=2.0 && spec_mat_weighted[i,j]<=2.0)){
      print("NA")
    }else if(spec_mat_flat[i,j]>=2.0 && spec_mat_weighted[i,j]<=2.0){ #get rid of this if statement 
      #which <- which((spec_mat_flat[,j]>=2.0 & spec_mat_weighted[,j]<=2.0))
      genes_spec[i,1]<- colnames(spec_mat_flat)[j]
      genes_spec[i,2]<- gene_names[i]
      genes_spec[i,3]<-spec_mat_flat[i,j] 
      genes_spec[i,4]<-spec_mat_weighted[i,j]
      genes_spec[i,5]<-(spec_mat_flat[i,j] - spec_mat_weighted[i,j])
      genes_spec[i,6]<-(spec_mat_weighted[i,j] - spec_mat_flat[i,j])
    }else{
      print("not specific")
    }
  }
}
########## 
vec1 <- character()
#diff_1<-character()
for(j in 1:ncol(spec_mat_weighted)){
 which<-which((spec_mat_flat[,j]>=2.0 & spec_mat_weighted[,j]<=2.0))
which<-as.matrix(which)
  which<- rownames(which)
  which<-str_split_fixed(which, "[.]", 2)
  which<- which[,1]
   vec1 <- c(vec1, which)
  # difference1<-as.character(which(spec_mat_flat[,j]>=2.0 & spec_mat_weighted[,j]<=2.0))
  # diff_1<-c(diff_1,difference1)
}


vec1<-unique(vec1) #unique vector for gene ids of flat >2 and weighted < 2 
#diff_1<-as.numeric(diff_1)
#hist(diff_1)



vec2 <- character()
#diff_2<-character()
for(j in 1:ncol(spec_mat_weighted)){
 which<-which((spec_mat_flat[,j]<=2.0 & spec_mat_weighted[,j]>=2.0))
which<-as.matrix(which)
  which<- rownames(which)
  which<-str_split_fixed(which, "[.]", 2)
  which<- which[,1]
   vec2 <- c(vec2, which)
 #   difference<-as.character(which(spec_mat_flat[,j]<=2.0 & spec_mat_weighted[,j]>=2.0))
  # diff_2<-c(diff_2,difference)
}

vec2<-unique(vec2)
#diff_2<-as.numeric(diff_2)
#hist(diff_2)

   



 
 
 
 


```
#plotting 
```{r}
data_spec<-as.data.frame(gene_names)
library(data.table)
colnames(data_spec)<- c("gene")
res_ids <- left_join(data_spec, annotations_ahb, by=c("gene"="gene_id")) 
res_ids




allOE_genes <- as.character(res_ids$gene)
## Extract significant results
sigOE <- vec2 #specific genes 
names(sigOE)<- c("gene_id")
sigOE_genes <- as.character(vec2) #specific genes 
names(sigOE_genes)<- c("gene_id")
View(allOE_genes)
View(sigOE_genes)
View(res_ids)

ego <- enrichGO(gene = sigOE_genes, 
                universe = allOE_genes,
                keyType = "ENSEMBL",
                OrgDb = org.Hs.eg.db, 
                ont = "BP", 
                pAdjustMethod = "BH",
                qvalueCutoff = 0.05,
                readable = TRUE)



cluster_summary <- data.frame(ego)
cluster_summary
write.csv(cluster_summary, "results/clusterProfiler_Mov10oe.csv")


dotplot(ego, showCategory=50)


png("weight>flat.png",width=1000,height=900)
dotplot(ego, showCategory=50)#top 20 
dev.off()

ego <- enrichplot::pairwise_termsim(ego)
png("weight>flat_dotplot.png",width=1000,height=900)
 emapplot(ego, showCategory = 20)
dev.off()

#reference package - methods 
#fraction that looks like brain 
#

```







