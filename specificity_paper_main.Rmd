---
title: "specificity_paper_main"
author: "Leroy Bondhus"
date: "8/19/2021"
output: html_document
---


## NOTE: most functions live in GeneSpecificityFuncs package for 
##       this project. Load this package here
## 
```{r set up package of functions used}
library("devtools")
library("roxygen2")
install("./../GeneSpecificityFuncs")
```

```{r libraries}
library(ggplot2)
```

## load gtex here
```{r import dataset}
## import gtex medians data
temp <- tempfile()
download.file("https://storage.googleapis.com/gtex_analysis_v8/rna_seq_data/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct.gz",temp)
gtex <- read.table( temp, skip=2, header = TRUE, sep = "\t")
gtex_rowinfo <- data.frame(Name=gtex$Name, Description=gtex$Description)
rownames(gtex) <- gtex$Name
gtex <- as.matrix(gtex[,3:ncol(gtex)])
unlink(temp); rm(temp)



library(biomaRt)
## import ensembl gene data
ensembl = useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl", GRCh=37)
genes <- getBM(attributes=c('chromosome_name','start_position','end_position','hgnc_symbol', 'ensembl_gene_id','gene_biotype'),
                 filters = list('biotype'='protein_coding'),
                 mart = ensembl, useCache = F) 
genes <- genes[which(is.element(genes$chromosome_name, c(1:22, "X", "Y", "MT")) & genes$hgnc_symbol != "" ) ,]



```

## clean gtex dataset here
```{r clean dataset}
## show mitochondrial genes drive a large part of sample similarity
## Note sum of medians in gtex not quite 1M - likely artifact of taking medians
barplot(colSums(gtex))
library(stringr)
## match genes between gtex and ensembl
gtex_names <- str_split_fixed(gtex_rowinfo$Name, "[.]", 2)[,1]
which <- which(genes$chromosome_name != "MT" )
gtex_cleaned <- gtex[which(is.element(gtex_names, genes$ensembl_gene_id[which])),]
which <- which(genes$chromosome_name == "MT" )
gtex_cleanedMT <- gtex[which(is.element(gtex_names, genes$ensembl_gene_id[which])),]

##non-mitochondrial TPM sum
barplot(colSums(gtex_cleaned))
##mitochondrial TPM sum
barplot(colSums(gtex_cleanedMT))
## non-mito + mito TPM sum
barplot(colSums(gtex_cleaned)+colSums(gtex_cleanedMT))
rm(gtex_cleanedMT)
##renormalize TPM without mitochondrial genes
for(i in 1:ncol(gtex_cleaned)){
  gtex_cleaned[,i] <- (gtex_cleaned[,i]*1e6 / sum(gtex_cleaned[,i]))
}
barplot(colSums(gtex_cleaned))

#### Supplemental Figure (Fraction of TPM from chr==M )
gtex <- gtex_cleaned; rm(gtex_cleaned)
exp_mat <- gtex
## log10(TPM+1) transform of data
exp_mat <- log10(exp_mat+1)

#### Supplemental Figure (heatmap cluster of samples )

## remove mitochondrial contribution
```


```{r measure sample similarity}
### to do: justify method for measuring sample similarity - may require comparison or refs
calc_zscore_matrix<- function(dat) {
  zscores <- dat; zscores[] <- 0 
  means <- rowMeans(dat)
  sds <- as.numeric(rep(NA,length(means)))
  which <- which(means != 0)
  sds[which] <- apply(dat[which,],1,sd)
  for(j in 1:ncol(dat)){zscores[,j] <- (dat[,j] - means)/sds  }
  return(zscores)
}

calc_dot_product_similarity_matrix <- function(dat) {
  dot_product_similarity_matrix <- matrix(0, nrow = ncol(dat), ncol = ncol(dat))
  colnames(dot_product_similarity_matrix) <- colnames(dat)
  rownames(dot_product_similarity_matrix) <- colnames(dat)
  for(i in 1:ncol(dat)){
    for(j in 1:ncol(dat)){
      which_i <- which(!is.na(dat[,i])) ## ignore NAs
      which_j <- which(!is.na(dat[,j])) ## ignore NAs
      dot_product_similarity_matrix[i,j] <- sum(dat[which_i,i] * dat[which_j,j]) / (norm(dat[which_i,i],"2")*norm(dat[which_j,j],"2"))
    }
  }
  return(dot_product_similarity_matrix)
}

## together these are a similarity function 
zscores <- calc_zscore_matrix(exp_mat) 
dot_sim <- calc_dot_product_similarity_matrix(zscores)

### validate choice
##use dist=1-dot_sim(zscores(log10(tpm+1))), single linkage clustering for now 
plot(hclust(as.dist(1-dot_sim),method = "single"), hang = -1, main = "dot_sim,single_clust")
sim_mat <- dot_sim
### create: sim_mat # sample similarity matrix
```


```{r hierarchical clustering on sample similarity}
### to do: justify method for hierarchical clustering - may require comparison or refs

sim_tree <- as.dendrogram(hclust(as.dist(1-dot_sim),method = "single"))

### create: sim_tree # sample similarity tree
```


```{r calculate sample weights}
### uses Equation 1. 
## modelled on Yenifer's code
add_dist_to_parent <- function(dend, dist_to_parent=0){
  ## note: distance to parent is fed in at the start of the function
  attributes(dend) <- c(attributes(dend), dist_to_parent=dist_to_parent)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    ## distance to parent is simply the difference in height between parent and child
    dist_to_parent <- attributes(dend)$height - attributes(dend[[i]])$height 
    dend[[i]] <- add_dist_to_parent(dend[[i]], 
                                             dist_to_parent = dist_to_parent)
  }
  return(dend)
}
sim_tree <- add_dist_to_parent(sim_tree)

## modelled on Yenifer's code
add_weights <- function(dend, weight_of_parent=0){
  weight <- (attributes(dend)$dist_to_parent / attributes(dend)$members) + weight_of_parent 
  attributes(dend) <- c(attributes(dend), weight=weight)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    dend[[i]] <- add_weights(dend[[i]], weight_of_parent=weight)
  }
  return(dend)
}
sim_tree <- add_weights(sim_tree)

## plot tree with weights
library(dendextend)
sim_tree %>% set("nodes_pch",19) %>% set("nodes_cex", 2.2*sqrt(get_nodes_attr(sim_tree,"weight"))) %>% plot


weights <- setNames(get_leaves_attr(sim_tree,"weight"),nm=get_leaves_attr(sim_tree,"lab") )


ggplot( data.frame(names=names(weights), weights=weights),aes(x=names, y=weights))+
  geom_col()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

### create: weights
```


```{r calculate specificity}
library(dplyr)
library('Hmisc')
## order weights to match columns of expression matrix
weights <- setNames(get_leaves_attr(sim_tree,"weight"),nm=get_leaves_attr(sim_tree,"lab") )
weights <- weights[order(factor(names(weights),levels = colnames(exp_mat)))]



# function to calculate weighted zscores
## was te_to_weighted_zscore
## now assumes weights are sorted in same order at mat samples
calc_weighted_zscore_matrix <- function(mat, weights){
  if(any( colnames(mat) != names(weights) )){print("WARNING: mismatch in weights names and matrix colnames order")}
  weighted_mat <- mat; weighted_mat[] <- 0
  for (i in 1:length(weights)){
    weighted_mat[,i] <- weights[i]*mat[,i]
  }
  weighted_means <- numeric(length = nrow(weighted_mat))
  sum_of_weights <- sum(weights)
  for (i in 1:nrow(weighted_mat)){
    weighted_means[i] <- sum(weighted_mat[i,]) / sum_of_weights
  }
  weighted_var <- numeric(length=nrow(mat))
  for (i in 1:nrow(mat)){
    weighted_var[i] <- wtd.var(mat[i,],weights=weights)
  }
  weighted_sd <- sqrt(weighted_var)
  for(i in 1:ncol(mat)){
    mat[,i] <- (mat[,i]-weighted_means)/weighted_sd
  }
  weighted_zscores <- mat
  return(weighted_zscores)
}

spec_mat_weighted <- calc_weighted_zscore_matrix(exp_mat, weights)
flat <- weights; flat[1:length(flat)] <- 1
spec_mat_flat  <- calc_weighted_zscore_matrix(exp_mat, flat)
plot(as.matrix(spec_mat_weighted),as.matrix(spec_mat_flat))
abline(h=c(0,2,4), v=c(0,2,4))
### use Roshni's Code



### creates: spec_mat # specificity matrix
```





```{r validation with variable sample set}
## for i in 1:num(brain_samples)
# get P1 and P2
# expression mat -> calc sample sim -> create tree -> calc weight -> specificity 
# save results
# compare

### generalizing a list to store results in - this will make it easier to extend later if necessary.
## Note: only need the weighted version of each equation as each simplifies to flat version when all weights are 1
specificity_measures <- list(func_names=c("Zscore", "Tau", "Tsi","Gini"),
                             funcs=list(Zscore=calc_weighted_zscore_matrix,
                                        Tau=NA,
                                        Tsi=NA,
                                        Gini=NA
                             ))
robustness_test_results <- list( )
for(i in 1:length(specificity_measures$func_names)){
  el_names <- paste( c("P1_weighted_", "P1_flat_", "P2_weighted_", "P2_flat_")
                     , specificity_measures$func_names[i], sep="")
  temp_list <- setNames(list(list(),list(),list(),list()), nm=el_names  )
  robustness_test_results <- c(robustness_test_results, temp_list )
}

### note: should add the weight calculation step inside this function
## e.g. Feed in P1, P2, n, num_perm,
## also Feed in similarity function, clustering function (since these might be variable later)
## calc similarity matrix -> calc similarity tree -> calc sample weights

library(doParallel)
library(foreach)
registerDoParallel(detectCores())



num_brain_samples <- length(colnames(exp_mat)[grep("[Bb]rain",colnames(exp_mat))])
## P1 and notP1 are contant throughout, so set these outside loops
P1 <- as.matrix(exp_mat[,grep("[Bb]rain",colnames(exp_mat), invert = TRUE)])
notP1 <- as.matrix(exp_mat[,grep("[Bb]rain",colnames(exp_mat), invert = FALSE)])
## use general similarity_func and cluster_func in case we want to test more later
similarity_func <- function(exp_mat){calc_dot_product_similarity_matrix(calc_zscore_matrix(exp_mat))}
cluster_func <- function(sim_mat){add_weights(add_dist_to_parent(as.dendrogram(hclust(as.dist(1-sim_mat), method = "single") ) ))}  

real_results <- foreach(n=1:num_brain_samples, .final = function(n) setNames(n,paste("n=",n,sep = ""))  ) %dopar% {
  for(measure in specificity_measures$func_names){
    ## P2_baseline is P1 + each column of P2 so we can calculate once before of rep's loop
    specificity_func <- specificity_measures$funcs[[measure]]
    if(is.na(specificity_func)){print(paste(measure, "func is NA")); next;}
    P2_flat_baseline <- matrix(nrow = nrow(notP1),ncol =  ncol(notP1))
    P2_weighted_baseline <- matrix(nrow = nrow(notP1),ncol =  ncol(notP1))
    for(i in colnames(notP1)){
      P1uP2 <- cbind(P1,notP1[,i,drop=F])
      sim_mat <- similarity_func(P1uP2)
      sim_tree <- cluster_func(sim_mat)
      ## get the weights in proper order
      weights <- setNames(get_leaves_attr(sim_tree,"weight"),nm=get_leaves_attr(sim_tree,"lab") )
      weights <- weights[order(factor(names(weights),levels = colnames(P1uP2)))]
      ## flat is equivalent to all weights equal to 1
      flat <- weights; flat[1:length(flat)] <- 1
      P2_flat_baseline[,i] <- specificity_func(P1uP2, flat)[,i]
      P2_weighted_baseline[,i] <- specificity_func(P1uP2, weights)[,i]
    }
    
    for(rep in 1:num_reps){
      ## P1_baseline should include 1 brain sample chosen at random, since this is random, we want to associate this within each replicate
      P1_baseline
      P2 <- notP1[,sample(1:ncol(notP1), n)]
      P1uP2 <- cbind(P1,P2)
      
    }
  }
}



```



