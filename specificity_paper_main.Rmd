---
title: "specificity_paper_main"
author: "Leroy Bondhus"
date: "8/19/2021"
output: html_document
---


## NOTE: most functions live in GeneSpecificityFuncs package for 
##       this project. Load this package here
## 
```{r set up package of functions used}
library("devtools")
library("roxygen2")
install("./../GeneSpecificityFuncs")
```

```{r libraries}
library(ggplot2)
```

## load gtex here
```{r import dataset}
## import gtex medians data
temp <- tempfile()
download.file("https://storage.googleapis.com/gtex_analysis_v8/rna_seq_data/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct.gz",temp)
gtex <- read.table( temp, skip=2, header = TRUE, sep = "\t")
unlink(temp); rm(temp)



library(biomaRt)
## import ensembl gene data
ensembl = useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl", GRCh=37)
genes <- getBM(attributes=c('chromosome_name','start_position','end_position','hgnc_symbol', 'ensembl_gene_id','gene_biotype'),
                 filters = list('biotype'='protein_coding'),
                 mart = ensembl, useCache = F) 
genes <- genes[which(is.element(genes$chromosome_name, c(1:22, "X", "Y", "MT")) & genes$hgnc_symbol != "" ) ,]



```

## clean gtex dataset here
```{r clean dataset}
## show mitochondrial genes drive a large part of sample similarity
## Note sum of medians in gtex not quite 1M - likely artifact of taking medians
barplot(colSums(gtex[,3:ncol(gtex)]))
which <- which(genes$chromosome_name != "MT" )
whichMT <- which(genes$chromosome_name == "MT" )
library(stringr)
## match genes between gtex and ensembl
gtex_names <- str_split_fixed(gtex$Name, "[.]", 2)[,1]
gtex_cleaned <- gtex[which(is.element(gtex_names, genes$ensembl_gene_id[which])),]
gtex_cleanedMT <- gtex[which(is.element(gtex_names, genes$ensembl_gene_id[whichMT])),]

##non-mitochondrial TPM sum
barplot(colSums(gtex_cleaned[,3:ncol(gtex_cleaned)]))
##mitochondrial TPM sum
barplot(colSums(gtex_cleanedMT[,3:ncol(gtex_cleanedMT)]))
## non-mito + mito TPM sum
barplot(colSums(gtex_cleaned[,3:ncol(gtex_cleaned)])+colSums(gtex_cleanedMT[,3:ncol(gtex_cleanedMT)]))

##renormalize TPM without mitochondrial genes
gtex_cleaned_renorm <- gtex_cleaned
for(i in 3:ncol(gtex_cleaned_renorm)){
  gtex_cleaned_renorm[,i] <- (gtex_cleaned_renorm[,i]*1e6 / sum(gtex_cleaned_renorm[,i]))
}
barplot(colSums(gtex_cleaned_renorm[,3:ncol(gtex_cleaned_renorm)]))

#### Supplemental Figure (Fraction of TPM from chr==M )
gtex <- gtex_cleaned_renorm
exp_mat <- gtex[,3:ncol(gtex)]
## log10(TPM+1) transform of data
exp_mat <- log10(exp_mat+1)
rownames(exp_mat) <- gtex$Name

#### Supplemental Figure (heatmap cluster of samples )

## remove mitochondrial contribution
```


```{r measure sample similarity}
### to do: justify method for measuring sample similarity - may require comparison or refs
calc_zscore_matrix<- function(dat) {
  zscores <- matrix(NA, nrow = nrow(dat), ncol = ncol(dat))
  means <- rowMeans(dat)
  sds <- as.numeric(rep(NA,length(means)))
  which <- which(means != 0)
  sds[which] <- apply(dat[which,],1,sd)
  for(j in 1:ncol(dat)){zscores[,j] <- (dat[,j] - means)/sds  }
  return(zscores)
}

calc_dot_product_similarity_matrix <- function(dat) {
  dot_product_similarity_matrix <- matrix(0, nrow = ncol(dat), ncol = ncol(dat))
  for(i in 1:ncol(dat)){
    for(j in 1:ncol(dat)){
      which_i <- which(!is.na(dat[,i])) ## ignore NAs
      which_j <- which(!is.na(dat[,j])) ## ignore NAs
      dot_product_similarity_matrix[i,j] <- sum(dat[which_i,i] * dat[which_j,j]) / (norm(dat[which_i,i],"2")*norm(dat[which_j,j],"2"))
    }
  }
  return(dot_product_similarity_matrix)
}

zscores <- calc_zscore_matrix(exp_mat) 
dot_sim <- calc_dot_product_similarity_matrix(zscores)
colnames(dot_sim) <- colnames(exp_mat)
rownames(dot_sim) <- colnames(exp_mat)

### validate choice
##use dist=1-dot_sim(zscores(log10(tpm+1))), single linkage clustering for now 
plot(hclust(as.dist(1-dot_sim),method = "single"), hang = -1, main = "dot_sim,single_clust")
sim_mat <- dot_sim
### create: sim_mat # sample similarity matrix
```


```{r hierarchical clustering on sample similarity}
### to do: justify method for hierarchical clustering - may require comparison or refs

sim_tree <- as.dendrogram(hclust(as.dist(1-dot_sim),method = "single"))

### create: sim_tree # sample similarity tree
```


```{r calculate sample weights}
### uses Equation 1. 
## modelled on Yenifer's code
LMB_dend.add_dist_to_parent <- function(dend, dist_to_parent=0){
  ## note: distance to parent is fed in at the start of the function
  attributes(dend) <- c(attributes(dend), dist_to_parent=dist_to_parent)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    ## distance to parent is simply the difference in height between parent and child
    dist_to_parent <- attributes(dend)$height - attributes(dend[[i]])$height 
    dend[[i]] <- LMB_dend.add_dist_to_parent(dend[[i]], 
                                             dist_to_parent = dist_to_parent)
  }
  return(dend)
}
sim_tree <- LMB_dend.add_dist_to_parent(sim_tree)

## modelled on Yenifer's code
LMB_dend.add_weights <- function(dend, weight_of_parent=0){
  weight <- (attributes(dend)$dist_to_parent / attributes(dend)$members) + weight_of_parent 
  attributes(dend) <- c(attributes(dend), weight=weight)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    dend[[i]] <- LMB_dend.add_weights(dend[[i]], weight_of_parent=weight)
  }
  return(dend)
}
sim_tree <- LMB_dend.add_weights(sim_tree)

## plot tree with weights
library(dendextend)
sim_tree %>% set("nodes_pch",19) %>% set("nodes_cex", 2.2*sqrt(get_nodes_attr(sim_tree,"weight"))) %>% plot


weights <- setNames(get_leaves_attr(sim_tree,"weight"),nm=get_leaves_attr(sim_tree,"lab") )


ggplot( data.frame(names=names(weights), weights=weights),aes(x=names, y=weights))+
  geom_col()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

### create: weights
```


```{r calculate specificity}
library(dplyr)
library('Hmisc')
## order weights to match columns of expression matrix
names(weights) <- factor(names(weights), levels = colnames(exp_mat))
weights <- weights[order(names(weights))]


# function to calculate weighted zscores
## was te_to_weighted_zscore
## now assumes weights are sorted in same order at mat samples
calc_weighted_zscore_matrix <- function(mat, weights){
  if(any( colnames(mat) != names(weights) )){print("WARNING: mismatch in weights names and matrix colnames order")}
  weighted_mat <- matrix(nrow=nrow(mat),ncol=ncol(mat))
  for (i in 1:length(weights)){
    weighted_mat[,i] <- weights[i]*mat[,i]
  }
  colnames(weighted_mat) <- colnames(mat)
  weighted_means <- numeric(length = nrow(weighted_mat))
  sum_of_weights <- sum(weights)
  for (i in 1:nrow(weighted_mat)){
    weighted_means[i] <- sum(weighted_mat[i,]) / sum_of_weights
  }
  weighted_var <- numeric(length=nrow(mat))
  for (i in 1:nrow(mat)){
    weighted_var[i] <- wtd.var(mat[i,],weights=weights)
  }
  weighted_sd <- sqrt(weighted_var)
  for (i in 1:nrow(mat)){
    mat[i,] <- (mat[i,]-weighted_means[i])/weighted_sd[i]
  }
  weighted_zscores <- na.omit(mat)
  return(weighted_zscores)
}

spec_mat <- calc_weighted_zscore_matrix(exp_mat, weights)

### use Roshni's Code



### creates: spec_mat # specificity matrix
```





```{r validation with variable sample set}
## for i in 1:num(brain_samples)
# get P1 and P2
# expression mat -> calc sample sim -> create tree -> calc weight -> specificity 
# save results
# compare

### generalizing a list to store results in - this will make it easier to extend later if necessary.
specificity_measures <- c("Zscore", "Tau", "Tsi","Gini")
robustness_test_results <- list( )
for(i in 1:length(specificity_measures)){
  el_names <- paste( c("P1_weighted_", "P1_flat_", "P2_weighted_", "P2_flat_")
                     , specificity_measures[i], sep="")
  temp_list <- setNames(list(list(),list(),list(),list()), nm=el_names  )
  robustness_test_results <- c(robustness_test_results, temp_list )
}

### note: should add the weight calculation step inside this function
## e.g. Feed in P1, P2, n, num_perm,
## also Feed in similarity function, clustering function (since these might be variable later)
## calc similarity matrix -> calc similarity tree -> calc sample weights

library(doParallel)
library(foreach)
registerDoParallel(detectCores())

test_results <- foreach(x=1:10, .final = function(x) setNames(x,paste("abc",1:10))  ) %dopar% {
  x
}

num_brain_samples <- length(colnames(exp_mat)[grep("[Bb]rain",colnames(exp_mat))])
real_results <- foreach(n=1:num_brain_samples, .final = function(n) setNames(n,paste("n=",n,sep = ""))  ) %dopar% {
  list("a","b",n)
}


appended_te_to_weighted_zscore <- function(P1,P2,weights,size_of_selection,number_of_permutations){
  results_list <- list()
  for (i in 1:size_of_selection){
    for (j in 1:number_of_permutations){
      selected_columns <- sample(P2, size_of_selection)
      df <- data.frame(P1,selected_columns)
      weights_sub <- left_join(data.frame(name=colnames(df)),weights,by="name")
      weighted_te_matrix <- matrix(nrow=nrow(df),ncol=ncol(df))
      for (i in 1:nrow(weight_vector)){
        weighted_te_matrix[,i] <- weight_vector[i,2]*df[,i]
      }
      colnames(weighted_te_matrix) <- colnames(df)
      weighted_means <- c(1:nrow(weighted_te_matrix))
      sum_of_weights <- sum(weight_vector[,2])
      for (i in 1:nrow(weighted_te_matrix)){
        weighted_means[i] <- sum(weighted_te_matrix[i,]) / sum_of_weights
      }
      weighted_var <- matrix(nrow=nrow(df),ncol=1)
      for (i in 1:nrow(df)){
        weighted_var[i] <- wtd.var(df[i,],weights=weight_vector[,2])
      }
      weighted_sd <- sqrt(weighted_var)
      for (i in 1:nrow(df)){
        df[i,] <- (df[i,]-weighted_means[i])/weighted_sd[i]
      }
      weighted_zscores <- na.omit(df)
      weighted_zscores <- weighted_zscores[,1:ncol(P1)]
      output <- list(weighted_zscores)
      results_list <- append(results_list,output)
    }
  }
  return(results_list)
}


```
