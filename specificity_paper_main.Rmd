---
title: "specificity_paper_main"
author: "Leroy Bondhus"
date: "8/19/2021"
output: html_document
---

```{r libraries}
library(ggplot2)
library(ggpubr)
library(biomaRt)
library(stringr)
library(dendextend)
library(dplyr)
library(Hmisc)
library(doParallel)
library(foreach)
registerDoParallel(detectCores())
library(ComplexHeatmap)
library(circlize)
```

## load gtex here
```{r import dataset}
## import gtex medians data
temp <- tempfile()
download.file("https://storage.googleapis.com/gtex_analysis_v8/rna_seq_data/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct.gz",temp)
gtex <- read.table( temp, skip=2, header = TRUE, sep = "\t")
gtex_rowinfo <- data.frame(Name=gtex$Name, Description=gtex$Description)
rownames(gtex) <- gtex$Name
gtex <- as.matrix(gtex[,3:ncol(gtex)])
unlink(temp); rm(temp)


## import ensembl gene data
ensembl = useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl", GRCh=37)
genes <- getBM(attributes=c('chromosome_name','start_position','end_position','hgnc_symbol', 'ensembl_gene_id','gene_biotype'),
                 filters = list('biotype'='protein_coding'),
                 mart = ensembl, useCache = F) 
genes <- genes[which(is.element(genes$chromosome_name, c(1:22, "X", "Y", "MT")) & genes$hgnc_symbol != "" ) ,]
```

## clean gtex dataset here
```{r clean dataset}
## show mitochondrial genes drive a large part of sample similarity
## Note sum of medians in gtex not quite 1M - likely artifact of taking medians
barplot(colSums(gtex))

## match genes between gtex and ensembl
gtex_names <- str_split_fixed(gtex_rowinfo$Name, "[.]", 2)[,1]
which <- which(genes$chromosome_name != "MT" )
gtex_cleaned <- gtex[which(is.element(gtex_names, genes$ensembl_gene_id[which])),]
which <- which(genes$chromosome_name == "MT" )
gtex_cleanedMT <- gtex[which(is.element(gtex_names, genes$ensembl_gene_id[which])),]

barplot(colSums(gtex_cleaned))     ##non-mitochondrial TPM sum
barplot(colSums(gtex_cleanedMT))   ##mitochondrial TPM sum
rm(gtex_cleanedMT)
##renormalize TPM without mitochondrial genes
for(i in 1:ncol(gtex_cleaned)){
  gtex_cleaned[,i] <- (gtex_cleaned[,i]*1e6 / sum(gtex_cleaned[,i]))
}
barplot(colSums(gtex_cleaned))

gtex <- gtex_cleaned; rm(gtex_cleaned)
exp_mat <- gtex
## log10(TPM+1) transform of data
exp_mat <- log10(exp_mat+1)

## remove mitochondrial contribution
```
```{r collected functions used }

calc_zscore_matrix<- function(dat) {
  zscores <- dat; zscores[] <- 0 
  means <- rowMeans(dat)
  sds <- as.numeric(rep(NA,length(means)))
  which <- which(means != 0)
  sds[which] <- apply(dat[which,],1,sd)
  for(j in 1:ncol(dat)){zscores[,j] <- (dat[,j] - means)/sds  }
  return(zscores)
}

calc_dot_product_similarity_matrix <- function(dat) {
  dot_product_similarity_matrix <- matrix(0, nrow = ncol(dat), ncol = ncol(dat))
  colnames(dot_product_similarity_matrix) <- colnames(dat)
  rownames(dot_product_similarity_matrix) <- colnames(dat)
  for(i in 1:ncol(dat)){
    for(j in 1:ncol(dat)){
      which_i <- which(!is.na(dat[,i])) ## ignore NAs
      which_j <- which(!is.na(dat[,j])) ## ignore NAs
      dot_product_similarity_matrix[i,j] <- sum(dat[which_i,i] * dat[which_j,j]) / (norm(dat[which_i,i],"2")*norm(dat[which_j,j],"2"))
    }
  }
  return(dot_product_similarity_matrix)
}

### uses Equation 1. 
## modelled on Yenifer's code
add_dist_to_parent <- function(dend, dist_to_parent=0){
  ## note: distance to parent is fed in at the start of the function
  attributes(dend) <- c(attributes(dend), dist_to_parent=dist_to_parent)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    ## distance to parent is simply the difference in height between parent and child
    dist_to_parent <- attributes(dend)$height - attributes(dend[[i]])$height 
    dend[[i]] <- add_dist_to_parent(dend[[i]], 
                                             dist_to_parent = dist_to_parent)
  }
  return(dend)
}

## this functions calculates and adds weights to dendrogram object using the 'dist_to_parent' attribute added previously
## weight_of_parent parameter exists only for recursion and should not be manually adjusted without understanding it's function
add_weights <- function(dend, weight_of_parent=0){
  weight <- (attributes(dend)$dist_to_parent / attributes(dend)$members) + weight_of_parent 
  attributes(dend) <- c(attributes(dend), weight=weight)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    dend[[i]] <- add_weights(dend[[i]], weight_of_parent=weight)
  }
  return(dend)
}

## this function returns the weights from a dendrogram object that has a "weight" attribute at leaves. Also requires the order of the vector to return based on names of leaves
get_weights <- function(dend, name_order){
  weights <- setNames(get_leaves_attr(dend,"weight"),nm=get_leaves_attr(dend,"lab") )
  weights <- weights[order(factor(names(weights),levels = name_order))]
  return(weights)
}


# function to calculate weighted zscores given matrix and vector of weights. column names of the matrix and names of the weight vector must match
calc_weighted_zscore_matrix <- function(mat, weights){
  if(any( colnames(mat) != names(weights) )){stop("WARNING: mismatch in weights names and matrix colnames order")}
  weighted_mat <- mat; weighted_mat[] <- 0
  for (i in 1:length(weights)){
    weighted_mat[,i] <- weights[i]*mat[,i]
  }
  weighted_means <- numeric(length = nrow(weighted_mat))
  sum_of_weights <- sum(weights)
  for (i in 1:nrow(weighted_mat)){
    weighted_means[i] <- sum(weighted_mat[i,]) / sum_of_weights
  }
  weighted_var <- numeric(length=nrow(mat))
  for (i in 1:nrow(mat)){
    weighted_var[i] <- wtd.var(mat[i,],weights=weights)
  }
  weighted_sd <- sqrt(weighted_var)
  for(i in 1:ncol(mat)){
    mat[,i] <- (mat[,i]-weighted_means)/weighted_sd
  }
  weighted_zscores <- mat
  return(weighted_zscores)
}

```

```{r organizing functions into lists}
### generalizing a list to store results in - this will make it easier to extend later if necessary.
## Note: only need the weighted version of each equation as each simplifies to flat version when all weights are 1
specificity_measures <- list(func_names=c("Zscore", "Tau", "Tsi","Gini"),
                             funcs=list(Zscore=calc_weighted_zscore_matrix,
                                        Tau=NA,
                                        Tsi=NA,
                                        Gini=NA
                             ))
## only 1 similarity function tested for now, can make as list later
similarity_func <- function(exp_mat){calc_dot_product_similarity_matrix(calc_zscore_matrix(exp_mat))}
## only 1 clustering fucntion tested for now, can make as a list later
cluster_func <- function(sim_mat){add_weights(add_dist_to_parent(as.dendrogram(hclust(as.dist(1-sim_mat), method = "single") ) ))}  

```


```{r measure sample similarity}

## dot similarity from initial Z scores
dot_sim <- similarity_func(exp_mat)
heatmap(dot_sim)


sim_tree <- cluster_func(dot_sim)
## plot similarity tree with weights
sim_tree %>% set("nodes_pch",19) %>% set("nodes_cex", 2.2*sqrt(get_nodes_attr(sim_tree,"weight"))) %>% plot


## take a look at the weights
weights <- get_weights(sim_tree, colnames(exp_mat))
ggplot( data.frame(names=names(weights), weights=weights),aes(x=names, y=weights))+
  geom_col()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))



spec_mat_weighted <- calc_weighted_zscore_matrix(exp_mat, weights)
flat <- weights; flat[1:length(flat)] <- 1
spec_mat_flat  <- calc_weighted_zscore_matrix(exp_mat, flat)
## plot to look at global dif between flat and weighted

```




```{r Figure_2C validation with variable sample set }

if(TRUE){  ## NOTE! This chunk can require a lot of memory and time depending if running sequential. If you want to look at robustness test results it is recommended you have enabled parallel computing (e.g. check getDoParWorkers > 3 or 4 (preferably more))
  
  ## Use this variable to control whether performing random or true brain-non-brain partition
  random_partition = FALSE
  
  
  robustness_test_results <- list( )
  for(i in 1:length(specificity_measures$func_names)){
    el_names <- paste( c( "P1_", "P2_")
                       , specificity_measures$func_names[i], sep="")
    temp_list <- setNames(list(list(), list()), nm=el_names  )
    robustness_test_results <- c(robustness_test_results, temp_list )
  }
  
  
  num_brain_samples <- length(colnames(exp_mat)[grep("[Bb]rain",colnames(exp_mat))])
  num_reps <- 5
  ## use general similarity_func and cluster_func in case we want to test more later
  similarity_func <- function(exp_mat){calc_dot_product_similarity_matrix(calc_zscore_matrix(exp_mat))}
  cluster_func <- function(sim_mat){add_weights(add_dist_to_parent(as.dendrogram(hclust(as.dist(1-sim_mat), method = "single") ) ))}  
  
  
  ## to switch analysis between True Brain Partition and equalivalent sized Random Partition set random_partition ##
  if(random_partition){
    which <- sample(1:ncol(exp_mat), length(grep("[Bb]rain",colnames(exp_mat),invert = TRUE)))
    P1 <- as.matrix(exp_mat[, which])
    notP1 <- as.matrix(exp_mat[, which(!is.element(1:ncol(exp_mat),which ))])
  }else{
    ## P1 and notP1 are contant throughout, so set these outside loops
    P1 <- as.matrix(exp_mat[,grep("[Bb]rain",colnames(exp_mat), invert = TRUE)])
    notP1 <- as.matrix(exp_mat[,grep("[Bb]rain",colnames(exp_mat), invert = FALSE)])
  }
  ### define 1-n trajectories ahead of time since i+1 should be referenced against i.
  ## do foreach over each element of permuation matrix ## use arrayInd to get row/col given perm number
  permutation_matrix <- matrix(nrow = num_brain_samples, ncol = num_reps )
  for(rep in 1:num_reps){
    permutation_matrix[,rep] <- sample(colnames(notP1),num_brain_samples, replace = FALSE)
  }
  
  
  for(measure in specificity_measures$func_names){
    specificity_func <- specificity_measures$funcs[[measure]]
    if(!is.function(specificity_func)){print(paste(measure, "func is not a function")); next;}
    
      results <- foreach(perm=1:length(permutation_matrix), .errorhandling = "pass", .final = function(x) setNames(x,paste("rep=", arrayInd(1:length(permutation_matrix), dim(permutation_matrix))[,2], ",n=", arrayInd(1:length(permutation_matrix), dim(permutation_matrix ))[,1], sep = ""))) %dopar% {
      library(Hmisc)
      library(dendextend)
      sample_indices <- 1:(arrayInd(perm, dim(permutation_matrix))[,1]) ## row is sample name, all names in a row up to top are choices for n=1,2..i
      rep_index <- arrayInd(perm, dim(permutation_matrix))[,2] ## column is replicate number
      sample_set <- permutation_matrix[sample_indices, rep_index]
      
      # P1_baseline is just P1 at n=1
      P2 <- notP1[,sample_set, drop=F]; colnames(P2) <- make.unique(colnames(P2)) ## make.unique will facilitate sampling with replacement
      P1uP2 <- cbind(P1,P2)
      
      ## P1uP2 ## exp_mat > get sim mat > get sim tree > get samp weights > get spec mat
      sim_mat <- similarity_func(P1uP2)
      sim_tree <- cluster_func(sim_mat)
      weights <- get_weights(sim_tree, colnames(P1uP2))
      flat <- weights; flat[] <- 1
      spec_mat_flat <- specificity_func(P1uP2, flat)
      spec_mat_weighted <- specificity_func(P1uP2, weights)
      
      # need to fill in these with spec_score matrices for each n for each method
      # names should match 
      ### restore once error fixed
      result <- list(
        P1_weighted_spec_score = spec_mat_weighted[,colnames(P1), drop=F],
        P1_flat_spec_score = spec_mat_flat[,colnames(P1), drop=F],
        P2_weighted_spec_score = spec_mat_weighted[,colnames(P2), drop=F],
        P2_flat_spec_score = spec_mat_flat[,colnames(P2), drop=F]
      )
      }
      
      results_P1 <- list()
      results_P2 <- list()
      for(i in 1:length(results)){
        name <- names(results)[i]
        rep <- str_split_fixed(names(results)[1], "[=,]", n=4)[,2]
        n <- str_split_fixed(names(results)[1], "[=,]", n=4)[,4]
        results_P1[[name]] <- list(P1_weighted_spec_score = results[[name]]$P1_weighted_spec_score, P1_flat_spec_score = results[[name]]$P1_flat_spec_score)
        results[[name]]$P1_weighted_spec_score <- NULL;  results[[name]]$P1_flat_spec_score <- NULL;  ## large object so delete as we go to avoid copy
        
        results_P2[[name]] <- list(P2_weighted_spec_score = results[[name]]$P2_weighted_spec_score, P2_flat_spec_score = results[[name]]$P2_flat_spec_score)
        results[[name]]$P2_weighted_spec_score <- NULL;  results[[name]]$P2_flat_spec_score<- NULL;  ## large object so delete as we go to avoid copy
      }
      
      robustness_test_results[[paste("P1_", measure,sep = "")]] <- results_P1; rm(results_P1)
      robustness_test_results[[paste("P2_", measure,sep = "")]] <- results_P2; rm(results_P2)
  }

  
} ## end of chunk control
## output to look at is robustness_test_results
```


```{r flat v weighted jaccard plot}
#system("mkdir figures")
figures_dir <- paste(getwd(),"figures", sep = "/")
date <- format(Sys.time(), format="%Y%m%d") 

## jaccard between n = 1 and n = num_brain_samples for brain v non-brain OR P1 v P2 

df <- data.frame(n=numeric(), rep=numeric(), cut_point=numeric(),
                 jaccard=numeric(), P1orP2=character(),
                 weighted=logical(), samp=character(),
                 gene_count=numeric(), gene_count_baseline=numeric(), gene_count_intersect=numeric())
## nested for loop builds df of jaccard results for plotting
Sys.time()
for(el in names(robustness_test_results)){
  if(length(robustness_test_results[[el]])==0 ){next;}
  P1orP2 <- str_split_fixed(el,"_",n=2)[1]
  measure <- str_split_fixed(el,"_",n=2)[2]
  if(measure == "Zscore"){cuts <- seq(0,4,0.5)   ## set cutoffs
  }else{ cuts <- seq(0,1,0.05)}
  
 # for(i in 1:length(robustness_test_results[[el]]) ){   ### foreach at this level if implementing foreach
  df_temp <- foreach(i=1:length(robustness_test_results[[el]]), .errorhandling = "pass", .combine = rbind) %dopar% {
    #foreach(perm=1:length(permutation_matrix), .errorhandling = "pass", .final = function(x) setNames(x,paste("rep=", arrayInd(1:length(permutation_matrix), dim(permutation_matrix))[,2], ",n=", arrayInd(1:length(permutation_matrix), dim(permutation_matrix ))[,1], sep = ""))) %dopar% {
    
    df_internal <- data.frame(n=numeric(), rep=numeric(), cut_point=numeric(),
                 jaccard=numeric(), P1orP2=character(),
                 weighted=logical(), samp=character(),
                 gene_count=numeric(), gene_count_baseline=numeric(), gene_count_intersect=numeric())
    
    n = as.numeric(str_split_fixed(names(robustness_test_results[[el]][i]), "[=,]", n=4 )[,4])
    rep = as.numeric(str_split_fixed(names(robustness_test_results[[el]][i]), "[=,]", n=4 )[,2])
    for(weighted_or_flat in c("weighted","flat")){
      baseline_name <- names(robustness_test_results[[el]])[grep(paste("rep=",rep,",n=",1,"$", sep = ""),names(robustness_test_results[[el]]) )]
      
      weighted_flat_index <- grep(weighted_or_flat,names(robustness_test_results[[el]][[baseline_name]]))
      baseline_mat <-  robustness_test_results[[el]][[baseline_name]][[weighted_flat_index]]
      
      weighted_flat_index <- grep(weighted_or_flat,names(robustness_test_results[[el]][[i]]))
      temp_mat <- robustness_test_results[[el]][[i]][[weighted_flat_index]][,colnames(baseline_mat),drop=FALSE]
      ncols <- ncol(temp_mat); ncuts <- length(cuts)
      temp_df <- data.frame(n=rep(n, ncols*ncuts), rep=rep(rep, ncols*ncuts), cut_point=numeric(length=ncols*ncuts),
                   jaccard=numeric(length=ncols*ncuts), P1orP2=rep(P1orP2, ncols*ncuts),
                   weighted=rep( grepl("weighted", weighted_or_flat), ncols*ncuts), samp=character(length=ncols*ncuts),
                   gene_count=numeric(length=ncols*ncuts), gene_count_baseline=numeric(length=ncols*ncuts),
                   gene_count_intersect=numeric(length=ncols*ncuts)  )
      for(s in 1:ncol(temp_mat) ){  ## add a row to df for each sample   
        for(cut_index in 1:length(cuts)){
          ind <- (s-1)*length(cuts)+cut_index  ### use arr_ind here instead
          temp_df[ind,]$cut_point <- cuts[cut_index]
          if(cuts[cut_index]<0){
            temp_df[ind,]$jaccard <- (  length( which( baseline_mat[,s] < cuts[cut_index] & temp_mat[,s] < cuts[cut_index]  )) /
                                        length( which( baseline_mat[,s] < cuts[cut_index] | temp_mat[,s] < cuts[cut_index]  )) )
            temp_df[ind,]$gene_count <-  length( which(temp_mat[,s] < cuts[cut_index]  ) )
            temp_df[ind,]$gene_count_baseline <- length( which(baseline_mat[,s] < cuts[cut_index]  ) ) 
            temp_df[ind,]$gene_count_intersect <-  length( which( baseline_mat[,s] < cuts[cut_index] & temp_mat[,s] < cuts[cut_index]  ))
          } else {
            temp_df[ind,]$jaccard <- (  length( which( baseline_mat[,s] > cuts[cut_index] & temp_mat[,s] > cuts[cut_index]  )) /
                                        length( which( baseline_mat[,s] > cuts[cut_index] | temp_mat[,s] > cuts[cut_index]  )) )
            temp_df[ind,]$gene_count <-  length( which(temp_mat[,s] > cuts[cut_index]  ) )
            temp_df[ind,]$gene_count_baseline <-  length( which(baseline_mat[,s] > cuts[cut_index]  ) )
            temp_df[ind,]$gene_count_intersect <-  length( which( baseline_mat[,s] > cuts[cut_index] & temp_mat[,s] > cuts[cut_index]  ))
          }
          temp_df[ind,]$samp <- unique(colnames(baseline_mat[,s,drop=FALSE] ),colnames(temp_mat[,s,drop=FALSE] ) )  
        }
      }
      df_internal <- rbind(df_internal, temp_df)
    }
    df_internal
  }
  df <- rbind(df, df_temp)
}
Sys.time()

#df$jaccard[which(is.na(df$jaccard))] <- 0

df_summary <-aggregate(df$jaccard, by=list(n=df$n,cut_point=df$cut_point,P1orP2=df$P1orP2,weighted=df$weighted,samp=df$samp),FUN=function(x) mean(x,na.rm=TRUE) ) 
names(df_summary)[length(names(df_summary))] <- "jaccard_mean"
df_summary$jaccard_sd <- aggregate(df$jaccard, by=list(n=df$n,cut_point=df$cut_point,P1orP2=df$P1orP2,weighted=df$weighted,samp=df$samp), FUN=function(x) sd(x,na.rm = TRUE) )$x 
df_summary$gene_count <- aggregate(df$gene_count, by=list(n=df$n,cut_point=df$cut_point,P1orP2=df$P1orP2,weighted=df$weighted,samp=df$samp), FUN=function(x) mean(x,na.rm = TRUE) )$x 
df_summary$gene_count_baseline <- aggregate(df$gene_count_baseline, by=list(n=df$n,cut_point=df$cut_point,P1orP2=df$P1orP2,weighted=df$weighted,samp=df$samp), FUN=function(x) mean(x,na.rm = TRUE) )$x 
df_summary$gene_count_intersect <- aggregate(df$gene_count_intersect, by=list(n=df$n,cut_point=df$cut_point,P1orP2=df$P1orP2,weighted=df$weighted,samp=df$samp), FUN=function(x) mean(x,na.rm = TRUE) )$x 


#df$brain <- grepl("Brain", df$samp)
df_summary_by_partition <-aggregate(df$jaccard, by=list(n=df$n,cut_point=df$cut_point,P1orP2=df$P1orP2,weighted=df$weighted), FUN=function(x) mean(x,na.rm=TRUE) )
names(df_summary_by_partition)[length(names(df_summary_by_partition))] <- "jaccard_mean"
df_summary_by_partition$jaccard_sd <- aggregate(df$jaccard, by=list(n=df$n,cut_point=df$cut_point,P1orP2=df$P1orP2,weighted=df$weighted), FUN=function(x) sd(x,na.rm = TRUE) )$x 
df_summary_by_partition$gene_count <- aggregate(df$gene_count, by=list(n=df$n,cut_point=df$cut_point,P1orP2=df$P1orP2,weighted=df$weighted), FUN=function(x) mean(x,na.rm = TRUE) )$x 
df_summary_by_partition$gene_count_baseline <- aggregate(df$gene_count_baseline, by=list(n=df$n,cut_point=df$cut_point,P1orP2=df$P1orP2,weighted=df$weighted), FUN=function(x) mean(x,na.rm = TRUE) )$x 
df_summary_by_partition$gene_count_intersect <- aggregate(df$gene_count_intersect, by=list(n=df$n,cut_point=df$cut_point,P1orP2=df$P1orP2,weighted=df$weighted), FUN=function(x) mean(x,na.rm = TRUE) )$x 




for(samp in unique(df_summary$samp)){
  gglist <- list()
  gg<-ggplot(df_summary[which(df_summary$samp==samp),], aes(x=cut_point, y=jaccard_mean, color=n, group=n))+
    ggtitle(paste(samp))+
    geom_line()+
    facet_wrap( ~ weighted)
  gglist <- append(gglist,list(gg))
  gg<-ggplot(df_summary[which(df_summary$samp==samp),], aes(x=cut_point, y=(gene_count/gene_count_baseline), color=n, group=n))+
    ggtitle(paste(samp,"frac_of_baseline_called"))+
    geom_line()+
    facet_wrap( ~ weighted)
  gglist <- append(gglist,list(gg))
  gg<-ggplot(df_summary[which(df_summary$samp==samp),], aes(x=cut_point, y=(gene_count-gene_count_intersect)/gene_count, color=n, group=n))+
    ggtitle(paste(samp,"frac_not_in_baseline"))+
    geom_line()+
    facet_wrap( ~ weighted)
  gglist <- append(gglist,list(gg))
  
  
  gg<-ggplot(df_summary[which(df_summary$samp==samp),], aes(x=cut_point, y=jaccard_mean, color=weighted, group=weighted))+
    ggtitle(paste(samp))+
    geom_line()+
    facet_wrap( n ~ ., strip.position = "top", nrow = n)
    #facet_wrap( n ~ P1orP2)
  gglist <- append(gglist,list(gg))
  
  gg <- ggarrange(plotlist=gglist, ncol=2, nrow=2)
  plot(gg)
  #ggsave(paste(temp_figures_dir, "/",samp,"_stats.png",sep=""),gg, device = "png", width = 8, height=6)
}



figures_dir
system(paste("mkdir ", figures_dir,"/jaccard_plot_testing",sep="")) 
temp_figures_dir <- paste(figures_dir,"/jaccard_plot_testing",sep="")
gglist <- list()

gg <- ggplot(df_summary_by_partition, aes(x=cut_point, y=jaccard_mean, ymin=jaccard_mean-jaccard_sd/num_reps,ymax=jaccard_mean+jaccard_sd/num_reps, group=n, fill=n))+
  ggtitle("jaccard index for P1 and  P2, weighted and flat measures")+
  geom_ribbon(alpha=.3)+
   geom_line(aes(color=n))+
  facet_wrap(P1orP2 ~ weighted, labeller=labeller(weighted=c("TRUE"="weighted", "FALSE"="flat")) )
gglist <- append(gglist,list(gg))

gg<-ggplot(df_summary_by_partition, aes(x=cut_point, y=(gene_count/gene_count_baseline), color=n, group=n))+
  ggtitle(paste("frac_of_baseline_called"))+
  geom_line()+
  facet_wrap(P1orP2 ~ weighted, labeller=labeller(weighted=c("TRUE"="weighted", "FALSE"="flat")) )
plot(gg)
gglist <- append(gglist,list(gg))


gg<-ggplot(df_summary_by_partition, aes(x=cut_point, y=(gene_count-gene_count_intersect)/gene_count, color=n, group=n))+
  ggtitle(paste("frac_not_in_baseline"))+
  geom_line()+
  facet_wrap(P1orP2 ~ weighted, labeller=labeller(weighted=c("TRUE"="weighted", "FALSE"="flat")) )
plot(gg)
gglist <- append(gglist,list(gg))




gg <- ggplot(df_summary_by_partition, aes(x=cut_point, y=jaccard_mean, ymin=jaccard_mean-jaccard_sd/num_reps,ymax=jaccard_mean+jaccard_sd/num_reps, group=weighted, fill=weighted))+
  ggtitle("jaccard index for P1 and  P2, weighted and flat measures")+
  geom_ribbon(alpha=.3)+
   geom_line(aes(color=weighted))+
   facet_grid( P1orP2 ~ n ,  labeller=labeller(weighted=c("TRUE"="weighted", "FALSE"="flat")) )
gglist <- append(gglist,list(gg))

gg<-ggplot(df_summary_by_partition, aes(x=cut_point, y=(gene_count/gene_count_baseline), color=weighted, group=weighted))+
  ggtitle(paste("frac_of_baseline_called"))+
  geom_line()+
  facet_grid(P1orP2 ~ n , labeller=labeller(weighted=c("TRUE"="weighted", "FALSE"="flat")) )
plot(gg)
gglist <- append(gglist,list(gg))


gg<-ggplot(df_summary_by_partition, aes(x=cut_point, y=(gene_count-gene_count_intersect)/gene_count, color=weighted, group=weighted))+
  ggtitle(paste("frac_not_in_baseline"))+
  geom_line()+
  facet_grid(P1orP2 ~ n , labeller=labeller(weighted=c("TRUE"="weighted", "FALSE"="flat")) )
plot(gg)
gglist <- append(gglist,list(gg))


gg<-ggplot(df_summary_by_partition, aes(x=cut_point, y=gene_count_baseline-gene_count_intersect, color=n, group=n))+
  ggtitle(paste("diff baseline - intersecet"))+
  geom_line()+
  facet_grid(P1orP2 ~ weighted , labeller=labeller(weighted=c("TRUE"="weighted", "FALSE"="flat")) )
plot(gg)
gglist <- append(gglist,list(gg))


gg<-ggplot(df_summary_by_partition, aes(x=cut_point, y=gene_count-gene_count_intersect, color=n, group=n))+
  ggtitle(paste("diff count-intersect "))+
  geom_line()+
  facet_grid(P1orP2 ~ weighted , labeller=labeller(weighted=c("TRUE"="weighted", "FALSE"="flat")) )
plot(gg)
gglist <- append(gglist,list(gg))



gg<-ggplot(df_summary_by_partition, aes(x=cut_point, y=gene_count_baseline-gene_count_intersect, color=weighted, group=weighted))+
  ggtitle(paste("diff baseline - intersecet"))+
  geom_line()+
  facet_grid(P1orP2 ~ n , labeller=labeller(weighted=c("TRUE"="weighted", "FALSE"="flat")) )
plot(gg)
gglist <- append(gglist,list(gg))


gg<-ggplot(df_summary_by_partition, aes(x=cut_point, y=gene_count-gene_count_intersect, color=weighted, group=weighted))+
  ggtitle(paste("diff count-intersect "))+
  geom_line()+
  facet_grid(P1orP2 ~ n , labeller=labeller(weighted=c("TRUE"="weighted", "FALSE"="flat")) )
plot(gg)
gglist <- append(gglist,list(gg))



gg<-ggplot(df_summary_by_partition, aes(x=cut_point, y=log10(gene_count_baseline-gene_count_intersect), color=n, group=n))+
  ggtitle(paste("diff baseline - intersecet"))+
  geom_line()+
  facet_grid(P1orP2 ~ weighted , labeller=labeller(weighted=c("TRUE"="weighted", "FALSE"="flat")) )
plot(gg)
gglist <- append(gglist,list(gg))

gg<-ggplot(df_summary_by_partition, aes(x=cut_point, y=log10(gene_count-gene_count_intersect), color=n, group=n))+
  ggtitle(paste("diff count-intersect "))+
  geom_line()+
  facet_grid(P1orP2 ~ weighted , labeller=labeller(weighted=c("TRUE"="weighted", "FALSE"="flat")) )
plot(gg)
gglist <- append(gglist,list(gg))


gg<-ggplot(df_summary_by_partition, aes(x=cut_point, y=log10(gene_count_baseline-gene_count_intersect), color=weighted, group=weighted))+
  ggtitle(paste("diff baseline - intersecet"))+
  geom_line()+
  facet_grid(P1orP2 ~ n , labeller=labeller(weighted=c("TRUE"="weighted", "FALSE"="flat")) )
plot(gg)
gglist <- append(gglist,list(gg))

gg<-ggplot(df_summary_by_partition, aes(x=cut_point, y=log10(gene_count-gene_count_intersect), color=weighted, group=weighted))+
  ggtitle(paste("diff count-intersect "))+
  geom_line()+
  facet_grid(P1orP2 ~ n , labeller=labeller(weighted=c("TRUE"="weighted", "FALSE"="flat")) )
plot(gg)
gglist <- append(gglist,list(gg))

for(i in 1:length(gglist)){
#  ggsave(filename = paste(temp_figures_dir,"/temp_",i,".png",sep=""), gglist[[i]], device="png", dpi = 200, width=6, height=4)
}

```

```{r testing aggregate}
head(state.x77)
aggregate(state.x77, list(Region = state.region), mean)

aggregate(df$jaccard, by=list(n=df$n,cut_point=df$cut_point,P1orP2=df$P1orP2,weighted=df$weighted,samp=df$samp), FUN=mean ) 
  
gg<-ggplot(df_summary[which(df_summary$samp==samp),], aes(x=cut_point, y=log10(overlap_count_mean), color=n, group=n))+
   ggtitle(paste(samp))+
   geom_line()+
   facet_wrap(~ weighted)
 plot(gg)
 

 ## weighted v flat (is weighted better?)
 ## as n increases (as dataset becomes more unbalanced)
 ## as Z increases (effect around 2-3 most critical)
 ## count baseline -  
 
```

```{r  flat v weighted comparisons}
if(FALSE){
  specificity_measures <- list(func_names=c("Zscore", "Tau", "Tsi","Gini"),
                             funcs=list(Zscore=calc_weighted_zscore_matrix,
                                        Tau=NA,
                                        Tsi=NA,
                                        Gini=NA
                             ))
similarity_func <- function(exp_mat){calc_dot_product_similarity_matrix(calc_zscore_matrix(exp_mat))}
cluster_func <- function(sim_mat){add_weights(add_dist_to_parent(as.dendrogram(hclust(as.dist(1-sim_mat), method = "single") ) ))}  


for(measure in specificity_measures$func_names){
  specificity_func <- specificity_measures$funcs[[measure]]
  if(!is.function(specificity_func)){print(paste(measure, "func is not a function")); next;}
  sim_mat <- similarity_func(exp_mat)
  sim_tree <- cluster_func(sim_mat)
  weights <- get_weights(sim_tree, colnames(exp_mat))
  flat <- weights; flat[] <- 1
  spec_mat_flat <- specificity_func(exp_mat, flat)
  spec_mat_weighted <- specificity_func(exp_mat, weights)
  

  col_fun = colorRamp2(c(-4, -2 ,0, 2, 4), c("black", "blue", "white", "yellow", "red"))
  
  delta_row_var <- abs(apply(spec_mat_flat, 1, var)
                       - apply(spec_mat_weighted, 1, var) )
  which <- order(delta_row_var, decreasing = TRUE)[1:10000]
  which <- which(delta_row_var > 0.3)
  h1 <- Heatmap(spec_mat_flat[which,], show_row_names = F, col=col_fun) #, row_order = 1:length(which))
  h1_list <- draw(h1)
  col_order <- column_order(h1_list)
  h1+
    Heatmap(spec_mat_weighted[which,], column_order = col_order, show_row_names = F, col=col_fun) #+
  #  Heatmap(abs(spec_mat_weighted[which,]-spec_mat_flat[which,]), column_order=col_order, show_row_names= F)
  
  gene_list <- list() 
  for(i in 1:ncol(spec_mat_weighted)){
    gene_list[[i]] <- list()
    gene_list[[i]] <- list(gene_list[[i]], rownames(spec_mat_flat)[order((spec_mat_weighted[,i]-spec_mat_flat[,i]), decreasing = TRUE)[1:5]])
  }
  for(i in 1:ncol(spec_mat_weighted)){
    gene_list[[ncol(spec_mat_weighted)+i]] <- list()
     gene_list[[ncol(spec_mat_weighted)+i]] <- list(gene_list[[i]], rownames(spec_mat_flat)[order((spec_mat_flat[,i]-spec_mat_weighted[,i]), decreasing = TRUE)[1:5]])
  }
 
  gene_list <- unique(unlist(gene_list))
  col_fun = colorRamp2(c(min(as.vector(spec_mat_flat[gene_list,]),as.vector(spec_mat_weighted[gene_list,]) ),
                         -2 ,0, 2, 4,
                         max(as.vector(spec_mat_flat[gene_list,]),as.vector(spec_mat_weighted[gene_list,]) )), c("black", "blue", "white", "yellow", "red", "red4"))
  
  h1 <- Heatmap(spec_mat_flat[gene_list,], show_row_names = F, col=col_fun, row_order = gene_list, column_order = colnames(spec_mat_flat) )
  h1_list <- draw(h1)
  col_order <- column_order(h1_list)
 # png(filename = "weighted_Z_minus_flat_Z_top10_bottom10_rawanddelta_each_tissue.png", width = 1620, height=1200)
  h1+
    Heatmap(spec_mat_weighted[gene_list,], column_order = col_order,  row_order = gene_list, show_row_names = F , col=col_fun) +
    
   # png(filename = "weighted_Z_minus_flat_Z_top10_bottom10_delta_each_tissue.png", width = 720, height=1200)
    Heatmap(spec_mat_weighted[gene_list,]-spec_mat_flat[gene_list,], column_order=col_order, row_order = gene_list, show_row_names= F)
  #dev.off()
}
  
  
  
## Sliding Jaccard Index  

df_sliding_jaccard <- data.frame(samp=character(), zcut=numeric(), jacc=numeric(), brain=logical(), unionsize=numeric() )
for(samp in colnames(spec_mat_flat)){
  for(zcut in seq(0,max(spec_mat_flat, na.rm = T)+1, by=0.25 )){
   vflat <- names(spec_mat_flat[which(spec_mat_flat[,samp] > zcut),samp])
   vweight <- names(spec_mat_weighted[which(spec_mat_weighted[,samp] > zcut),samp])
   jacc <-length(intersect(vflat,vweight))/length(union(vflat,vweight))
   brain <- grepl("Brain", samp)
   df_temp <- data.frame(samp=samp,zcut=zcut,jacc=jacc, brain=brain, unionsize=length(union(vflat,vweight)) )
   df_sliding_jaccard <- rbind(df_sliding_jaccard, df_temp)
  }
}

ggplot(df_sliding_jaccard[which(rowSums(is.na(df_sliding_jaccard))==0),], aes(x=zcut,y=jacc, color=samp))+
  geom_line()
ggplot(df_sliding_jaccard[which(df_sliding_jaccard$brain & rowSums(is.na(df_sliding_jaccard))==0),], aes(x=zcut,y=jacc, color=samp))+
  geom_line()
ggplot(df_sliding_jaccard[which(!df_sliding_jaccard$brain & rowSums(is.na(df_sliding_jaccard))==0),], aes(x=zcut,y=jacc, color=samp))+
  geom_line()

#png(filename = "jaccard_weighted_v_flat_slidingzcut_bbrainvnotbrain.png", width = 1620, height=720)
ggplot(df_sliding_jaccard[which(rowSums(is.na(df_sliding_jaccard))==0),], aes(x=zcut,y=jacc))+
  geom_line(aes( color=samp, color=unionsize))+
  facet_wrap(~brain)
#dev.off()
}
```
