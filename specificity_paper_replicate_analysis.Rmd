---
title: "specificity_paper_replicate_analysis"
author: "Leroy Bondhus"
date: "2/22/2022"
output: html_document
---


```{r libraries, include=FALSE}
library(ggplot2)
library(ggpubr)
library(biomaRt)
library(stringr)
library(dendextend)
library(dplyr)
library(Hmisc)
library(doParallel)
library(foreach)

library(ComplexHeatmap)
library(circlize)
library(scales)
library(reldist)
library(gridExtra)

library(DOSE)
library(pathview)
library(clusterProfiler)
library(org.Hs.eg.db)

library(tidyverse)
library(topGO) 
library(enrichplot)

library(data.table)

figures_dir <- paste(getwd(),"figures", sep = "/")
date <- format(Sys.time(), format="%Y%m%d") 

registerDoParallel(detectCores()-1)
```

## load gtex here
```{r import dataset}
## import gtex medians data
temp <- tempfile(fileext = ".gz")
download.file("https://storage.googleapis.com/gtex_analysis_v8/rna_seq_data/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_tpm.gct.gz",temp)
gtex <- data.table::fread(temp, skip=2, header = TRUE, sep = "\t")
gtex_rowinfo <- data.frame(Name=gtex$Name, Description=gtex$Description)
rownames(gtex) <- gtex$Name
gtex <- as.matrix(gtex[,3:ncol(gtex)])
rownames(gtex) <- gtex_rowinfo$Name
unlink(temp); rm(temp)

## import ensembl colinfo 
temp <- tempfile(fileext = ".txt")
download.file("https://storage.googleapis.com/gtex_analysis_v8/annotations/GTEx_Analysis_v8_Annotations_SampleAttributesDS.txt",temp)
gtex_colinfo <- data.table::fread(temp, skip=0, header = TRUE, sep = "\t")
unlink(temp); rm(temp)

temp <- tempfile(fileext = ".xlsx")
download.file("https://storage.googleapis.com/gtex_analysis_v8/annotations/GTEx_Analysis_v8_Annotations_SampleAttributesDD.xlsx",temp)
gtex_colheader_info <- readxl::read_excel(temp)
unlink(temp); rm(temp)
```

## clean gtex dataset here
```{r clean dataset, fig.width = 8, fig.height=4}
## subset gtex data
gtex_cols <-gtex_colinfo$SAMPID[which(gtex_colinfo$SMRIN >= 6 &
                                        gtex_colinfo$SMMPPD > 5e7 &
                                        gtex_colinfo$SMMPPDPR > 1e7)]
gtex <- gtex[ ,gtex_cols[is.element(gtex_cols, colnames(gtex) )]]

## import ensembl gene data
ensembl = useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl", GRCh=37)
genes <- getBM(attributes=c('chromosome_name','start_position','end_position','hgnc_symbol', 'ensembl_gene_id','gene_biotype'),
                 filters = list('biotype'='protein_coding'),
                 mart = ensembl, useCache = F) 
genes <- genes[which(is.element(genes$chromosome_name, c(1:22, "X", "Y", "MT")) & genes$hgnc_symbol != "" ) ,]



temp <- data.frame(names=colnames(gtex[,1:100]), total_transcripts=colSums(gtex[,1:100]))
ggplot( temp ,aes(y=total_transcripts, x=names))+
  geom_col()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

## match genes between gtex and ensembl
gtex_names <- str_split_fixed(gtex_rowinfo$Name, "[.]", 2)[,1]
which <- which(genes$chromosome_name == "MT" )
gtex_mt <- gtex[which(is.element(gtex_names, genes$ensembl_gene_id[which])),]
which <- which(genes$chromosome_name != "MT" )
gtex <- gtex[which(is.element(gtex_names, genes$ensembl_gene_id[which])),]


temp <- data.frame(names=colnames(gtex[,1:100]), total_transcripts=colSums(gtex[,1:100]))
ggplot( temp ,aes(y=total_transcripts, x=names))+
  geom_col()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
temp <- data.frame(names=colnames(gtex_mt[,1:100]), total_transcripts=colSums(gtex_mt[,1:100]))
ggplot( temp ,aes(y=total_transcripts, x=names))+
  geom_col()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


##renormalize TPM without mitochondrial genes
for(i in 1:ncol(gtex)){
  gtex[,i] <- (gtex[,i]*1e6 / sum(gtex[,i]))
}

temp <- data.frame(names=colnames(gtex[,1:100]), total_transcripts=colSums(gtex[,1:100]))
ggplot( temp ,aes(y=total_transcripts, x=names))+
  geom_col()+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

## log10(TPM+1) transform of data
exp_mat <- log10(gtex+1)


## median normalization
temp <- exp_mat[,1:100]
temp[which(temp==0 | is.infinite(temp))] <- NA
boxplot(temp)
median_normalize <- TRUE
if(median_normalize){
  for(i in 1:ncol(exp_mat)){
    exp_mat[,i] <- exp_mat[,i] / median(exp_mat[,i][which(exp_mat[,i] > 0)])
  }
}
temp <- exp_mat[,1:100]
temp[which(temp==0)] <- NA
boxplot(temp)


```


```{r collected functions used, include=FALSE}

calc_zscore_matrix<- function(dat) {
  zscores <- dat; zscores[] <- 0 
  means <- rowMeans(dat)
  sds <- as.numeric(rep(NA,length(means)))
  which <- which(means != 0)
  sds[which] <- apply(dat[which,],1,sd)
  for(j in 1:ncol(dat)){zscores[,j] <- (dat[,j] - means)/sds  }
  return(zscores)
}

calc_dot_product_similarity_matrix <- function(dat) {
  dot_product_similarity_matrix <- matrix(0, nrow = ncol(dat), ncol = ncol(dat))
  colnames(dot_product_similarity_matrix) <- colnames(dat)
  rownames(dot_product_similarity_matrix) <- colnames(dat)
  for(i in 1:ncol(dat)){
    for(j in 1:ncol(dat)){
      which_i <- which(!is.na(dat[,i])) ## ignore NAs
      which_j <- which(!is.na(dat[,j])) ## ignore NAs
      dot_product_similarity_matrix[i,j] <- sum(dat[which_i,i] * dat[which_j,j]) / (norm(dat[which_i,i],"2")*norm(dat[which_j,j],"2"))
    }
  }
  return(dot_product_similarity_matrix)
}

### uses Equation 1. from paper 
add_dist_to_parent <- function(dend, dist_to_parent=0){
  ## note: distance to parent is fed in at the start of the function
  attributes(dend) <- c(attributes(dend), dist_to_parent=dist_to_parent)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    ## distance to parent is simply the difference in height between parent and child
    dist_to_parent <- attributes(dend)$height - attributes(dend[[i]])$height 
    dend[[i]] <- add_dist_to_parent(dend[[i]], 
                                             dist_to_parent = dist_to_parent)
  }
  return(dend)
}

## this functions calculates and adds weights to dendrogram object using the 'dist_to_parent' attribute added previously
## weight_of_parent parameter exists only for recursion and should not be manually adjusted without understanding it's function
add_weights <- function(dend, weight_of_parent=0){
  weight <- (attributes(dend)$dist_to_parent / attributes(dend)$members) + weight_of_parent 
  attributes(dend) <- c(attributes(dend), weight=weight)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    dend[[i]] <- add_weights(dend[[i]], weight_of_parent=weight)
  }
  return(dend)
}

## this function returns the weights from a dendrogram object that has a "weight" attribute at leaves. Also requires the order of the vector to return based on names of leaves
get_weights <- function(dend, name_order){
  weights <- setNames(get_leaves_attr(dend,"weight"),nm=get_leaves_attr(dend,"lab") )
  weights <- weights[order(factor(names(weights),levels = name_order))]
  return(weights)
}


# function to calculate weighted zscores given matrix and vector of weights. column names of the matrix and names of the weight vector must match
calc_weighted_zscore_matrix <- function(mat, weights){
  if(any( colnames(mat) != names(weights) )){stop("WARNING: mismatch in weights names and matrix colnames order")}
  weighted_mat <- mat; weighted_mat[] <- 0
  for (i in 1:length(weights)){
    weighted_mat[,i] <- weights[i]*mat[,i]
  }
  weighted_means <- numeric(length = nrow(weighted_mat))
  sum_of_weights <- sum(weights)
  for (i in 1:nrow(weighted_mat)){
    weighted_means[i] <- sum(weighted_mat[i,]) / sum_of_weights
  }
  weighted_var <- numeric(length=nrow(mat))
  for (i in 1:nrow(mat)){
    weighted_var[i] <- Hmisc::wtd.var(mat[i,],weights=weights)
  }
  weighted_sd <- sqrt(weighted_var)
  for(i in 1:ncol(mat)){
    mat[,i] <- (mat[,i]-weighted_means)/weighted_sd
  }
  weighted_zscores <- mat
  return(weighted_zscores)
}



# weighted tau
calc_weighted_tau <- function(te_matrix, weights_vector){
  xhat_matrix <- matrix(nrow=nrow(te_matrix),ncol=ncol(te_matrix))
  te_row_maxima <- apply(te_matrix, 1, max)
  for(j in 1:ncol(te_matrix)){
    xhat_matrix[,j] <- te_matrix[,j] / te_row_maxima
  }
  temp_matrix <- matrix(nrow=nrow(te_matrix),ncol=ncol(te_matrix))
  for (i in 1:nrow(te_matrix)){
    temp_matrix[i,] <- weights_vector - (xhat_matrix[i,] * weights_vector)
  }
  tau <- numeric(length = nrow(temp_matrix))
  for (i in 1:nrow(temp_matrix)){
    temp <- sum(temp_matrix[i,]) / (sum(weights_vector) - weights_vector[which.max(temp_matrix[i,])])
    tau[i] <- ifelse(length(temp)==0,NA,temp)
  }
  
  ## add normalization (believe this is a numeric instability issue from dividing small numbers)
  # tau <- tau / max(tau, na.rm=T)
  ## alternative, set all > 1 to 1 (when looking at plots for different cutoffs, normalizing true 1 values causes issue)
  tau[which(tau > 1)] <- 1
  return(tau)
}

calc_weighted_tsi <- function(te_matrix,weights_vector){
  weighted_matrix <- t(apply(te_matrix,1, "*", weights_vector))
  tsi <- rowMax(weighted_matrix) / rowSums(weighted_matrix)
  return(tsi)
}


calc_weighted_gini <- function(te_matrix, weights_vector){
   gini_values <-  c()
  for (i in 1:nrow(te_matrix)){
    temp <- as.numeric(te_matrix[i,])
    temp <- reldist::gini(temp, weights_vector)
    gini_values <- append(gini_values,temp)
  }
  return(gini_values)
}


```
```{r organizing functions into lists, include=FALSE}
### generalizing a list to store results in - this will make it easier to extend later if necessary.
## Note: only need the weighted version of each equation as each simplifies to flat version when all weights are 1
specificity_measures <- list(func_names=c("Zscore", "Tau", "Tsi","Gini"),
                             funcs=list(Zscore=calc_weighted_zscore_matrix,
                                        Tau=calc_weighted_tau,
                                        Tsi=calc_weighted_tsi,
                                        Gini=calc_weighted_gini),
                             out_type=list(Zscore="matrix",
                                           Tau="vector",
                                           Tsi="vector",
                                           Gini="vector")
                             )
## only 1 similarity function tested for now, can make as list later
similarity_func <- function(exp_mat){calc_dot_product_similarity_matrix(calc_zscore_matrix(exp_mat))}
## only 1 clustering fucntion tested for now, can make as a list later
cluster_func <- function(sim_mat){add_weights(add_dist_to_parent(as.dendrogram(hclust(as.dist(1-sim_mat), method = "single") ) ))}  

```


```{r balanced v unbalanced in technical replicates redundant and non-redundant }
### 3 each sample type specific and general rep 5x report mean and stdev for correlation for flat and weighted
### gtex sample proportion, (max 10 each), sample type specifici and general rep 5x report mean and stdev for correlation for flat and weighted


```