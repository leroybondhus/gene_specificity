---
title: "specificity_paper_single_cell_analyses"
author: "Leroy Bondhus"
date: "2/23/2022"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r libraries, include=FALSE}
library(ggplot2)
library(ggpubr)
library(biomaRt)
library(stringr)
library(dendextend)
library(dplyr)
library(Hmisc)
library(doParallel)
library(foreach)

library(ComplexHeatmap)
library(circlize)
library(scales)
library(reldist)
library(gridExtra)

library(DOSE)
library(pathview)
library(clusterProfiler)
library(org.Hs.eg.db)

library(tidyverse)
library(topGO) 
library(enrichplot)

library(data.table)

figures_dir <- paste(getwd(),"figures", sep = "/")
data_dir <- paste(getwd(),"data", sep = "/")
date <- format(Sys.time(), format="%Y%m%d") 

registerDoParallel(detectCores()-2)
```


```{r download mouse scRNA datasets here}

### if download speed via R is too slow, can also manually download files from https://figshare.com/articles/dataset/HCL_DGE_Data/7235471 ##
download.file("https://figshare.com/ndownloader/files/22447898", paste(data_dir,"annotation_rmbatch_data_revised417.zip",sep="/"))
unzip(paste(data_dir,"annotation_rmbatch_data_revised417.zip",sep="/"), exdir=data_dir)

download.file("https://figshare.com/ndownloader/files/23043329", paste(data_dir,"dge_rmbatch_data.tar.gz",sep="/"))
untar(paste(data_dir,"dge_rmbatch_data.tar.gz",sep="/"),exdir=data_dir)

files <- list.files(path="./data/annotation_rmbatch_data_revised417",pattern="*.csv", full.names = T)
rm(anno)
for(f in files){
  temp <- fread(f)
  if(!exists("anno")){
    anno <- fread(f)
  } else{
    anno <- rbind(anno, temp,fill=TRUE)
  }
}

anno$V15 <- anno$V16 <- anno$V17 <- NULL
anno$Celltype_comb <- tolower(str_replace(anno$Celltype, "_.*gh","" ))

files <- list.files(path="./data/new",pattern="*.txt.gz", full.names = T)
rownames_genes <- foreach(f=files, .combine="c") %dopar% {
  rownames_genes <- fread(f)$V1
  rownames_genes
}
rownames_genes <- unique(rownames_genes)

rm(exp_mat)
## foreach crashing r if called over too many files at once-  break into chunks and aggregate 1 chunk at a time
file_chunks <- split(files, cut(seq_along(files), 10, labels = F))
for(i in 1:length(file_chunks)){
  print(i)
  temp_mat <- foreach(f=file_chunks[[i]], .combine = "+") %dopar% {
      temp_mat <- matrix(0, nrow=length(rownames_genes), ncol=length(unique(anno$Celltype_comb)) )
      colnames(temp_mat) <- unique(anno$Celltype_comb)
      rownames(temp_mat) <- rownames_genes
      raw_exp <- fread(f)
      rownames(raw_exp) <- raw_exp$V1
      raw_exp$V1 <- NULL
      cts <- unique(anno$Celltype_comb[which(is.element(anno$Cell_id, colnames(raw_exp)))])
      for(ct in cts){
        temp_mat[rownames(raw_exp),ct] <-  temp_mat[rownames(raw_exp),ct]+
          rowSums(as.matrix(raw_exp)[,which(is.element(colnames(raw_exp),anno$Cell_id[which(anno$Celltype_comb==ct)]  ))])
      }
      temp_mat
  }
  if(!exists("exp_mat")){
    exp_mat <- temp_mat
  } else {
    exp_mat <- exp_mat + temp_mat
  }
}

mouse_exp_mat <- exp_mat
save(mouse_exp_mat, file = "mouse_sc.Rdata")
load("mouse_sc.Rdata")
fwrite(mouse_exp_mat,file="mouse_sc.csv")
```

```{r download zebrafish scRNA datasets here}

mat <- fread("https://cells.ucsc.edu/zebrafish-dev/exprMatrix.tsv.gz")
meta <- data.frame(fread("https://cells.ucsc.edu/zebrafish-dev/meta.tsv"), row.names=1)
rownames(mat) <- mat$gene
mat$gene <- NULL

cts <- unique(meta$Cluster)
exp_mat <- matrix(0, nrow = nrow(mat),ncol = length(cts) )
rownames(exp_mat) <- rownames(mat)
colnames(exp_mat) <- cts

mat <- as.matrix(mat)
rownames(mat) <- rownames(exp_mat)
for(ct in cts){
  exp_mat[,ct] <- rowSums(mat[,which(is.element(colnames(mat), rownames(meta)[which(meta$Cluster == ct)]))] )
}

save(zebrafish_exp_mat, file="zebrafish_sc.Rdata")
zebrafish_exp_mat <- exp_mat
load("zebrafish_sc.Rdata")
fwrite(zebrafish_exp_mat,file="zebrafish_sc.csv")
```

##download gtex
```{r}
## import gtex medians data
temp <- tempfile()
download.file("https://storage.googleapis.com/gtex_analysis_v8/rna_seq_data/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct.gz",temp)
gtex <- read.table( temp, skip=2, header = TRUE, sep = "\t")
gtex_rowinfo <- data.frame(Name=gtex$Name, Description=gtex$Description)
rownames(gtex) <- gtex$Name
gtex <- as.matrix(gtex[,3:ncol(gtex)])
unlink(temp); rm(temp)
```


```{r setup gene lists}
## import mouse single cell data

## import zebrafish single cell data

## import human gene data
## import mouse gene data
## import zerbrafish gene data

## import human-mouse, human-zebrafish, mouse-zebrafish, human-mouse-zebrafish gene maps

genes_list <- list()
ensembl <- useEnsembl(biomart="ensembl", dataset="hsapiens_gene_ensembl", version="105")

genes_list[["hsapiens"]] <-  getBM(attributes=c('chromosome_name','start_position','end_position',
                                                'ensembl_gene_id',
                                                'mmusculus_homolog_ensembl_gene','drerio_homolog_ensembl_gene'),
                                   filters = list('biotype'='protein_coding'),
                                   mart = ensembl, useCache = F)
genes_list[["hsapiens"]] <-  merge(genes_list[["hsapiens"]], getBM(attributes=c(
                                                'ensembl_gene_id','gene_biotype', 'external_gene_name'),
                                   filters = list('biotype'='protein_coding'),
                                   mart = ensembl, useCache = F))
ensembl <- useEnsembl(biomart="ensembl", dataset="mmusculus_gene_ensembl", version="105")
genes_list[["mmusculus"]] <-  getBM(attributes=c('chromosome_name','start_position','end_position',
                                                'ensembl_gene_id',
                                                'hsapiens_homolog_ensembl_gene','drerio_homolog_ensembl_gene'),
                                   filters = list('biotype'='protein_coding'),
                                   mart = ensembl, useCache = F)
genes_list[["mmusculus"]] <-  merge(genes_list[["mmusculus"]], getBM(attributes=c(
                                                'ensembl_gene_id','gene_biotype', 'external_gene_name'),
                                   filters = list('biotype'='protein_coding'),
                                   mart = ensembl, useCache = F))

ensembl <- useEnsembl(biomart="ensembl", dataset="drerio_gene_ensembl", version="105")
genes_list[["drerio"]] <-  getBM(attributes=c('chromosome_name','start_position','end_position',
                                                'ensembl_gene_id',
                                                'hsapiens_homolog_ensembl_gene','mmusculus_homolog_ensembl_gene'),
                                   filters = list('biotype'='protein_coding'),
                                   mart = ensembl, useCache = F)
genes_list[["drerio"]] <-  merge(genes_list[["drerio"]], getBM(attributes=c(
                                                'ensembl_gene_id','gene_biotype', 'external_gene_name'),
                                   filters = list('biotype'='protein_coding'),
                                   mart = ensembl, useCache = F))

genes_list[["all"]] <- rbind(data.frame(cbind("hsapiens_gene_id"=genes_list$hsapiens$ensembl_gene_id,
                                              "mmusculus_gene_id"=genes_list$hsapiens$mmusculus_homolog_ensembl_gene,
                                              "drerio_gene_id"=genes_list$hsapiens$drerio_homolog_ensembl_gene)),
                             data.frame(cbind("hsapiens_gene_id"=genes_list$mmusculus$hsapiens_homolog_ensembl_gene,
                                              "mmusculus_gene_id"=genes_list$mmusculus$ensembl_gene_id,
                                              "drerio_gene_id"=genes_list$mmusculus$drerio_homolog_ensembl_gene)),
                             data.frame(cbind("hsapiens_gene_id"=genes_list$drerio$hsapiens_homolog_ensembl_gene, 
                                              "mmusculus_gene_id"=genes_list$drerio$mmusculus_homolog_ensembl_gene,
                                              "drerio_gene_id"=genes_list$drerio$ensembl_gene_id)))

## subset for all genes with 1:1:1 mapping only (i.e. avoid issue of multiple mapping when comparing similarity of expression profiles)
genes_list$all <- unique(genes_list$all)
genes_list$all <- genes_list$all[is.element(genes_list$all$hsapiens_gene_id, names(which(table(genes_list$all$hsapiens_gene_id)==1))),]
genes_list$all <- genes_list$all[is.element(genes_list$all$mmusculus_gene_id, names(which(table(genes_list$all$mmusculus_gene_id)==1))),]
genes_list$all <- genes_list$all[is.element(genes_list$all$drerio_gene_id, names(which(table(genes_list$all$drerio_gene_id)==1))),]
```

### clean exp datasets here
```{r}
exp_mat_raw_list <- list(mmusculus = mouse_exp_mat, drerio = zebrafish_exp_mat, hsapiens = gtex)
exp_mat_list <- list(mmusculus=NA, drerio=NA, hsapiens=NA)


### strip non-protein coding genes

which <- which(is.element(tolower(rownames(exp_mat_raw_list$mmusculus)),tolower(genes_list$mmusculus$external_gene_name) ))
exp_mat_raw_list$mmusculus <- exp_mat_raw_list$mmusculus[which,]
rownames(exp_mat_raw_list$mmusculus) <- unique(genes_list$mmusculus$ensembl_gene_id)[match( 
  tolower(rownames(exp_mat_raw_list$mmusculus)),
  tolower(unique(genes_list$mmusculus$external_gene_name)))]


which <- which(is.element(str_split_fixed(rownames(exp_mat_raw_list$drerio),"\\|",2)[,1], genes_list$drerio$ensembl_gene_id ))
exp_mat_raw_list$drerio <- exp_mat_raw_list$drerio[which,]
rownames(exp_mat_raw_list$drerio) <- unique(genes_list$drerio$ensembl_gene_id)[match(
  str_split_fixed(rownames(exp_mat_raw_list$drerio),"\\|",2)[,1], unique(genes_list$drerio$ensembl_gene_id))]


which <- which(is.element(str_split_fixed(rownames(exp_mat_raw_list$hsapiens),"\\.",2)[,1],genes_list$hsapiens$ensembl_gene_id ))
exp_mat_raw_list$hsapiens <- exp_mat_raw_list$hsapiens[which,]
rownames(exp_mat_raw_list$hsapiens) <- unique(genes_list$hsapiens$ensembl_gene_id)[match(
  str_split_fixed(rownames(exp_mat_raw_list$hsapiens),"\\.",2)[,1],unique(genes_list$hsapiens$ensembl_gene_id) 
)]


### strip mitochondrial genes
for(sp in names(exp_mat_raw_list) ){
  which <- which(is.element(rownames(exp_mat_raw_list[[sp]]),
                            genes_list[[sp]]$ensembl_gene_id[grep("MT-", 
                              genes_list[[sp]]$external_gene_name, ignore.case = TRUE)]), )
  exp_mat_raw_list[[sp]] <- exp_mat_raw_list[[sp]][-which,]
  barplot(log10(colSums(exp_mat_raw_list[[sp]])+1))
}

for(sp in names(exp_mat_raw_list) ){
  barplot(log10(colSums(exp_mat_raw_list[[sp]])+1))
  print(sum((colSums(exp_mat_raw_list[[sp]]) > 1e5 )))
  
  ## filter for cell types with at least 100k reads total
  exp_mat_raw_list[[sp]] <- exp_mat_raw_list[[sp]][,which(colSums(exp_mat_raw_list[[sp]]) > 1e5 )]
  exp_mat_raw_list[[sp]] <- t(apply((exp_mat_raw_list[[sp]]*1e6), 1, "/", colSums(exp_mat_raw_list[[sp]]) ))
  ## set all very low counts to zero to avoid variable read depth issues
  exp_mat_raw_list[[sp]][which(exp_mat_raw_list[[sp]] < 10)] <- 0
  exp_mat_raw_list[[sp]] <- t(apply((exp_mat_raw_list[[sp]]*1e6), 1, "/", colSums(exp_mat_raw_list[[sp]]) ))
  
  barplot(log10(colSums(exp_mat_raw_list[[sp]])+1))
  print(sum((colSums(exp_mat_raw_list[[sp]]) )))
}
### renormalize

## median normalization
exp_mat_list <- exp_mat_raw_list
for(sp in names(exp_mat_list) ){
  exp_mat_list[[sp]] <- log10(exp_mat_list[[sp]] + 1) 
  temp <- exp_mat_list[[sp]]
  temp[which(temp==0 | is.infinite(temp))] <- NA
  boxplot(temp)
  median_normalize <- TRUE
  if(median_normalize){
    for(i in 1:ncol(exp_mat_list[[sp]])){
       exp_mat_list[[sp]][,i] <- exp_mat_list[[sp]][,i] / median(exp_mat_list[[sp]][,i][which(exp_mat_list[[sp]][,i] > 0)])
    }
  }
  temp <- exp_mat_list[[sp]]
  temp[which(temp==0)] <- NA
  boxplot(temp)
}
```

```{r collected functions used, include=FALSE}

calc_zscore_matrix<- function(dat) {
  zscores <- dat; zscores[] <- 0 
  means <- rowMeans(dat)
  sds <- as.numeric(rep(NA,length(means)))
  which <- which(means != 0)
  sds[which] <- apply(dat[which,],1,sd)
  for(j in 1:ncol(dat)){zscores[,j] <- (dat[,j] - means)/sds  }
  return(zscores)
}

calc_dot_product_similarity_matrix <- function(dat) {
  dot_product_similarity_matrix <- matrix(0, nrow = ncol(dat), ncol = ncol(dat))
  colnames(dot_product_similarity_matrix) <- colnames(dat)
  rownames(dot_product_similarity_matrix) <- colnames(dat)
  for(i in 1:ncol(dat)){
    for(j in 1:ncol(dat)){
      which_i <- which(!is.na(dat[,i])) ## ignore NAs
      which_j <- which(!is.na(dat[,j])) ## ignore NAs
      dot_product_similarity_matrix[i,j] <- sum(dat[which_i,i] * dat[which_j,j]) / (norm(dat[which_i,i],"2")*norm(dat[which_j,j],"2"))
    }
  }
  return(dot_product_similarity_matrix)
}

### uses Equation 1. from paper 
add_dist_to_parent <- function(dend, dist_to_parent=0){
  ## note: distance to parent is fed in at the start of the function
  attributes(dend) <- c(attributes(dend), dist_to_parent=dist_to_parent)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    ## distance to parent is simply the difference in height between parent and child
    dist_to_parent <- attributes(dend)$height - attributes(dend[[i]])$height 
    dend[[i]] <- add_dist_to_parent(dend[[i]], 
                                             dist_to_parent = dist_to_parent)
  }
  return(dend)
}

## this functions calculates and adds weights to dendrogram object using the 'dist_to_parent' attribute added previously
## weight_of_parent parameter exists only for recursion and should not be manually adjusted without understanding it's function
add_weights <- function(dend, weight_of_parent=0){
  weight <- (attributes(dend)$dist_to_parent / attributes(dend)$members) + weight_of_parent 
  attributes(dend) <- c(attributes(dend), weight=weight)
  ## test if at leaf node
  if(!is.null(attributes(dend)$leaf) && attributes(dend)$leaf){
    return(dend)
  }
  for(i in 1:length(dend)){ ## length of dend should be number of child nodes
    dend[[i]] <- add_weights(dend[[i]], weight_of_parent=weight)
  }
  return(dend)
}

## this function returns the weights from a dendrogram object that has a "weight" attribute at leaves. Also requires the order of the vector to return based on names of leaves
get_weights <- function(dend, name_order){
  weights <- setNames(get_leaves_attr(dend,"weight"),nm=get_leaves_attr(dend,"lab") )
  weights <- weights[order(factor(names(weights),levels = name_order))]
  return(weights)
}


# function to calculate weighted zscores given matrix and vector of weights. column names of the matrix and names of the weight vector must match
calc_weighted_zscore_matrix <- function(mat, weights){
  if(any( colnames(mat) != names(weights) )){stop("WARNING: mismatch in weights names and matrix colnames order")}
  weighted_mat <- mat; weighted_mat[] <- 0
  for (i in 1:length(weights)){
    weighted_mat[,i] <- weights[i]*mat[,i]
  }
  weighted_means <- numeric(length = nrow(weighted_mat))
  sum_of_weights <- sum(weights)
  for (i in 1:nrow(weighted_mat)){
    weighted_means[i] <- sum(weighted_mat[i,]) / sum_of_weights
  }
  weighted_var <- numeric(length=nrow(mat))
  for (i in 1:nrow(mat)){
    weighted_var[i] <- Hmisc::wtd.var(mat[i,],weights=weights)
  }
  weighted_sd <- sqrt(weighted_var)
  for(i in 1:ncol(mat)){
    mat[,i] <- (mat[,i]-weighted_means)/weighted_sd
  }
  weighted_zscores <- mat
  return(weighted_zscores)
}



# weighted tau
calc_weighted_tau <- function(te_matrix, weights_vector){
  xhat_matrix <- matrix(nrow=nrow(te_matrix),ncol=ncol(te_matrix))
  te_row_maxima <- apply(te_matrix, 1, max)
  for(j in 1:ncol(te_matrix)){
    xhat_matrix[,j] <- te_matrix[,j] / te_row_maxima
  }
  temp_matrix <- matrix(nrow=nrow(te_matrix),ncol=ncol(te_matrix))
  for (i in 1:nrow(te_matrix)){
    temp_matrix[i,] <- weights_vector - (xhat_matrix[i,] * weights_vector)
  }
  tau <- c()
  den <- sum(weights_vector) - 1
  for (i in 1:nrow(temp_matrix)){
    temp <- sum(temp_matrix[i,]) / den
    tau <- append(tau,temp)
  }
  
  ## add normalization (believe this is a numeric instability issue from dividing small numbers)
  # tau <- tau / max(tau, na.rm=T)
  ## alternative, set all > 1 to 1 (when looking at plots for different cutoffs, normalizing true 1 values causes issue)
  tau[which(tau > 1)] <- 1
  return(tau)
}

calc_weighted_tsi <- function(te_matrix,weights_vector){
  tsi <- c()
  weights_vector <- as.matrix(weights_vector)
  weighted_matrix <- matrix(nrow=nrow(te_matrix),ncol=ncol(te_matrix))
  for (m in 1:nrow(weights_vector)){
    weighted_matrix[,m] <- weights_vector[m,1]*te_matrix[,m]
  }
  for (i in 1:nrow(te_matrix)){
    num <- max(weighted_matrix[i,])
    den <- sum(weighted_matrix[i,])
    temp <- num/den
    tsi <- append(tsi,temp)
  }
  return(tsi)
}

calc_weighted_gini <- function(te_matrix, weights_vector){
   gini_values <-  c()
  for (i in 1:nrow(te_matrix)){
    temp <- as.numeric(te_matrix[i,])
    temp <- reldist::gini(temp, weights_vector)
    gini_values <- append(gini_values,temp)
  }
  return(gini_values)
}


```

```{r organizing functions into lists, include=FALSE}
### generalizing a list to store results in - this will make it easier to extend later if necessary.
## Note: only need the weighted version of each equation as each simplifies to flat version when all weights are 1
specificity_measures <- list(func_names=c("Zscore", "Tau", "Tsi","Gini"),
                             funcs=list(Zscore=calc_weighted_zscore_matrix,
                                        Tau=calc_weighted_tau,
                                        Tsi=calc_weighted_tsi,
                                        Gini=calc_weighted_gini),
                             out_type=list(Zscore="matrix",
                                           Tau="vector",
                                           Tsi="vector",
                                           Gini="vector")
                             )
## only 1 similarity function tested for now, can make as list later
similarity_func <- function(exp_mat){calc_dot_product_similarity_matrix(calc_zscore_matrix(exp_mat))}
## only 1 clustering fucntion tested for now, can make as a list later
cluster_func <- function(sim_mat){add_weights(add_dist_to_parent(as.dendrogram(hclust(as.dist(1-sim_mat), method = "average") ) ))}  

```




### analyze each dataset in turn
```{r}

## need a function that can return list of all samples clustered within cutoff distance

group_samples_by_dend_dist <- function(tree, cutoff_dist){
  ## if tree height is less than cutoff, return all descendent node labels as a vector
  if(get_nodes_attr(tree, "height")[1] < cutoff_dist){
    return( list(get_leaves_attr(tree, "label") ) )
  }
  samp_groups <- list()
  for(i in 1:length(tree)){
    temp_groups <- group_samples_by_dend_dist(tree[[i]], cutoff_dist)
    samp_groups <- c(samp_groups, temp_groups)
  }
  return(samp_groups)
}

results_list <- list()
for(exp_mat_id in 1:length(exp_mat_list) ){
  exp_mat <- exp_mat_list[[exp_mat_id]]
  ## dot similarity from initial Z scores
  dot_sim <- similarity_func(exp_mat)
  sim_tree <- cluster_func(dot_sim)
  
  # filename = paste(figures_dir, "/", names(exp_mat_list)[exp_mat_id], "sample_similarity_heatmap.png", sep="")
  # png(filename = filename, width=10, height=10, units="in", res=250)
  heatmap(dot_sim, Rowv = rev(sim_tree), Colv = sim_tree, scale = "none", margins=c(11,13))
  # dev.off()
  
  sim_tree <- cluster_func(dot_sim)
  ## plot similarity tree with weights
#  filename = paste(figures_dir, "/", names(exp_mat_list)[exp_mat_id], "weighted_tree.png", sep="")
#  png(filename = filename, width=24, height=6, units="in", res=250)
#  par(mar = c(15,2,2,2))
  sim_tree %>% dendextend::set("nodes_pch",16) %>% dendextend::set("nodes_cex", 1.5*sqrt(get_nodes_attr(sim_tree,"weight"))) %>% plot
#  dev.off()
  
  ## make balanced subsets to compare include several reps several + add statistical test for difference in correlation
  num_reps <- 2
  dist_cutoff <- 0.5
  sample_groups <- group_samples_by_dend_dist(sim_tree, dist_cutoff) 
  ### artificially unbalance sample_groups
  sample_groups_lengths <- unlist(lapply(sample_groups, length))
  which_deep <- order(sample_groups_lengths, decreasing = TRUE)[1:2]
  which_shallow <- which(sample_groups_lengths < 3)
  
  unbalanced_sample_sets <- list()
  balanced_sample_sets <- list()
  for(i in 1:num_reps){
    ### downsample more shallowly sampled clusters to exaggerate dataset imbalance 
    temp_sample_groups <- sample_groups[c(which_deep, sample(which_shallow, sum(sample_groups_lengths[which_deep]) ) ) ]
    
    unbalanced_sample_sets[[i]] <- unlist(temp_sample_groups)
    temp_sample_set <- c()
    for(j in 1:length(temp_sample_groups)){
      temp_sample_set <- c(temp_sample_set, sample(temp_sample_groups[[j]],1) )
    }
    balanced_sample_sets[[i]] <- temp_sample_set 
  } 
  
  ### for each measure get unbalanced once, each balanced, get cor between each balanced and unbalanced for flat and weighted
  
  run_df <- merge(merge(data.frame(measure=specificity_measures$func_names),
                        data.frame(weighted=c(T,F))),
                  data.frame(balanced=T,rep=rep(1:num_reps)))
  run_df <- rbind(run_df,
                  merge(merge(data.frame(measure=specificity_measures$func_names),
                              data.frame(weighted=c(T,F))),
                        data.frame(balanced=F,rep=1:num_reps)))
  
  results <- foreach(run=1:nrow(run_df), .errorhandling = "pass",
                     .final = function(x) setNames(x,paste(run_df$measure,
                                                           "__weighted_", run_df$weighted,
                                                           "__balanced_", run_df$balanced,
                                                           "__rep_",run_df$rep,sep=""))) %dopar% {
    library(dendextend)
    specificity_func <- specificity_measures$funcs[[run_df$measure[run]]]
    if(run_df$balanced[run]){
      exp_mat_subset <- exp_mat[,balanced_sample_sets[[run_df$rep[run]]]]
    } else {
      exp_mat_subset <- exp_mat[,unbalanced_sample_sets[[run_df$rep[[run]]]]]
    }
    sim_mat_subset <- similarity_func(exp_mat_subset)
    sim_tree_subset <- cluster_func(sim_mat_subset)
    weights_subset <- get_weights(sim_tree_subset, colnames(exp_mat_subset))
    if(!run_df$weighted[run]){
      weights_subset[] <- 1
    }
    spec_mat_subset <- specificity_func(exp_mat_subset, weights_subset)
    if(run_df$measure[run] != "Zscore"){
      names(spec_mat_subset) <- rownames(exp_mat_subset)
    }
    spec_mat_subset
   }
  results_list[[names(exp_mat_list)[exp_mat_id]]] <- list(
    spec_results = results,
    balanced_sample_sets = balanced_sample_sets,
    unbalanced_sample_sets = unbalanced_sample_sets,
    run_df = run_df
  )
  
}
  
```

```{r plots for correlation}

result_plot_df_list <- list(
  balanced_v_unbalanced = data.frame(
    dataset = character(),
    measure = character(),
    weighted = logical(),
    rep = numeric(),
    gene = character(),
    balanced_spec = numeric(),
    unbalanced_spec = numeric()
  ),
  balanced_v_unbalanced_cor = data.frame(
    dataset = character(),
    measure = character(),
    weighted = logical(),
    rep = numeric(),
    cor = numeric()
  )
)

for(results_list_id in 1:length(results_list)){
  results <- results_list[[results_list_id]]$spec_results
  balanced_sample_sets <- results_list[[results_list_id]]$balanced_sample_sets
  unbalanced_sample_sets <- results_list[[results_list_id]]$unbalanced_sample_sets
  run_df <- results_list[[results_list_id]]$run_df
  
  for( i in 1:length(results)){
    measure <- str_split_fixed(names(results)[i], "__", 4)[1]
    weighted <- grepl("TRUE",str_split_fixed(names(results)[i], "__", 4)[2])
    balanced <- grepl("TRUE",str_split_fixed(names(results)[i], "__", 4)[3])
    rep <- as.numeric(str_split_fixed(str_split_fixed(names(results)[i], "__", 4)[4],"_",2)[2])
    if(balanced){next}
    
    result <- results[[i]]
    result_pair <- results[[str_replace(names(results)[i], "balanced_FALSE", "balanced_TRUE")]]
    
    
    ## store plot of balanced v unbalanced specificity estimate (model on supp 4)
    if(measure=="Zscore"){
      temp <- reshape2::melt(result[,colnames(result_pair)], value.name = "unbalanced_spec")
      temp2 <- reshape2::melt(result_pair, value.name = "balanced_spec")
      temp <- merge(temp, temp2);rm(temp2)
    } else {
      temp <- data.frame(
        Var1 = names(result),
        balanced_spec = result_pair,
        unbalanced_spec = result
      )
    }
    result_plot_df_list$balanced_v_unbalanced <- rbind(
      result_plot_df_list$balanced_v_unbalanced,
      data.frame(
        dataset = names(results_list)[results_list_id],
        measure = measure,
        weighted = weighted,
        rep = rep,
        gene = temp$Var1,
        balanced_spec = temp$balanced_spec,
        unbalanced_spec = temp$unbalanced_spec
        )
      )
    rm(temp)
    
    ## store correlation to data.frame (will use to get mean and stdev)
    if(measure=="Zscore"){
      temp <- cor( as.vector(result[,colnames(result_pair)]), as.vector(result_pair), use="pairwise.complete" )
    } else {
      temp <- cor( as.vector(result), as.vector(result_pair), use="pairwise.complete" )
    }
    
    result_plot_df_list$balanced_v_unbalanced_cor <- rbind(
      result_plot_df_list$balanced_v_unbalanced_cor,
      data.frame(
        dataset = names(results_list)[results_list_id],
        measure = measure,
        weighted = weighted,
        rep = rep,
        cor = temp
      )
    )
    
    ## store plot modelled on Figure 3A/B
    ## store plot modelled on 3D with GO enrichment in top diff genes 
    
    
  }
}
```



